('Seen labels:\t', {'raccoon': 1})
('Given labels:\t', [u'raccoon'])
('Overlap labels:\t', set(['raccoon']))
(13, 13)
detection layer nb_box 5
detection layer nb_class 1
output after conv2d sahpe
Tensor("DetectionLayer/BiasAdd:0", shape=(?, 13, 13, 30), dtype=float32)
grid_h 13
grid_w 13
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 224, 224, 3)  0                                            
__________________________________________________________________________________________________
model_1 (Model)                 (None, 13, 13, 512)  722496      input_1[0][0]                    
__________________________________________________________________________________________________
DetectionLayer (Conv2D)         (None, 13, 13, 30)   15390       model_1[1][0]                    
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 13, 13, 5, 6) 0           DetectionLayer[0][0]             
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 1, 1, 1, 10,  0                                            
__________________________________________________________________________________________________
lambda_1 (Lambda)               (None, 13, 13, 5, 6) 0           reshape_1[0][0]                  
                                                                 input_2[0][0]                    
==================================================================================================
Total params: 737,886
Trainable params: 737,886
Non-trainable params: 0
__________________________________________________________________________________________________
grid_w 13
Epoch 1/10
 - 2s - loss: 10.2547 - val_loss: 10.2440

Epoch 00001: val_loss improved from inf to 10.24402, saving model to best_squeezenet.h5
Epoch 2/10
Parsing Inputs...
 - 12s - loss: 10.2357 - val_loss: 10.2246

Epoch 00002: val_loss improved from 10.24402 to 10.22461, saving model to best_squeezenet.h5
Epoch 3/10
 - 1s - loss: 10.2165 - val_loss: 10.2104

Epoch 00003: val_loss improved from 10.22461 to 10.21037, saving model to best_squeezenet.h5
Epoch 4/10
 - 1s - loss: 6.2972 - val_loss: 5.4364

Epoch 00004: val_loss improved from 10.21037 to 5.43637, saving model to best_squeezenet.h5
Epoch 5/10
 - 1s - loss: 5.6189 - val_loss: 5.3476

Epoch 00005: val_loss improved from 5.43637 to 5.34763, saving model to best_squeezenet.h5
Epoch 6/10
 - 1s - loss: 6.0700 - val_loss: 5.2276

Epoch 00006: val_loss improved from 5.34763 to 5.22759, saving model to best_squeezenet.h5
Epoch 7/10
 - 1s - loss: 5.1100 - val_loss: 5.0863

Epoch 00007: val_loss improved from 5.22759 to 5.08627, saving model to best_squeezenet.h5
Epoch 8/10
 - 1s - loss: 5.8465 - val_loss: 4.9608

Epoch 00008: val_loss improved from 5.08627 to 4.96078, saving model to best_squeezenet.h5
Epoch 9/10
 - 1s - loss: 5.1932 - val_loss: 4.7992

Epoch 00009: val_loss improved from 4.96078 to 4.79920, saving model to best_squeezenet.h5
Epoch 10/10
 - 1s - loss: 4.6711 - val_loss: 4.6549

Epoch 00010: val_loss improved from 4.79920 to 4.65493, saving model to best_squeezenet.h5
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================
node name | # float_ops
_TFProfRoot (--/1.49b flops)
  model_1/fire2/expand3x3/convolution (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire3/expand3x3/convolution_grad/Conv2DBackpropInput (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire3/expand3x3/convolution_grad/Conv2DBackpropFilter (55.76m/55.76m flops)
  model_1/fire3/expand3x3/convolution (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire2/expand3x3/convolution_grad/Conv2DBackpropFilter (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire2/expand3x3/convolution_grad/Conv2DBackpropInput (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire4/expand3x3/convolution_grad/Conv2DBackpropFilter (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire4/expand3x3/convolution_grad/Conv2DBackpropInput (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire5/expand3x3/convolution_grad/Conv2DBackpropFilter (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire5/expand3x3/convolution_grad/Conv2DBackpropInput (53.75m/53.75m flops)
  model_1/fire4/expand3x3/convolution (53.75m/53.75m flops)
  model_1/fire5/expand3x3/convolution (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire8/expand3x3/convolution_grad/Conv2DBackpropFilter (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire8/expand3x3/convolution_grad/Conv2DBackpropInput (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire9/expand3x3/convolution_grad/Conv2DBackpropFilter (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire9/expand3x3/convolution_grad/Conv2DBackpropInput (49.84m/49.84m flops)
  model_1/fire8/expand3x3/convolution (49.84m/49.84m flops)
  model_1/fire9/expand3x3/convolution (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire7/expand3x3/convolution_grad/Conv2DBackpropInput (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire7/expand3x3/convolution_grad/Conv2DBackpropFilter (28.04m/28.04m flops)
  model_1/fire6/expand3x3/convolution (28.04m/28.04m flops)
  model_1/fire7/expand3x3/convolution (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire6/expand3x3/convolution_grad/Conv2DBackpropInput (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire6/expand3x3/convolution_grad/Conv2DBackpropFilter (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire3/squeeze1x1/convolution_grad/Conv2DBackpropInput (12.39m/12.39m flops)
  training/Adam/gradients/model_1/fire3/squeeze1x1/convolution_grad/Conv2DBackpropFilter (12.39m/12.39m flops)
  model_1/fire3/squeeze1x1/convolution (12.39m/12.39m flops)
  model_1/fire5/squeeze1x1/convolution (11.94m/11.94m flops)
  training/Adam/gradients/model_1/fire5/squeeze1x1/convolution_grad/Conv2DBackpropFilter (11.94m/11.94m flops)
  training/Adam/gradients/model_1/fire5/squeeze1x1/convolution_grad/Conv2DBackpropInput (11.94m/11.94m flops)
  model_1/fire9/squeeze1x1/convolution (11.08m/11.08m flops)
  training/Adam/gradients/model_1/fire9/squeeze1x1/convolution_grad/Conv2DBackpropFilter (11.08m/11.08m flops)
  training/Adam/gradients/model_1/fire9/squeeze1x1/convolution_grad/Conv2DBackpropInput (11.08m/11.08m flops)
  model_1/fire8/squeeze1x1/convolution (8.31m/8.31m flops)
  training/Adam/gradients/model_1/fire8/squeeze1x1/convolution_grad/Conv2DBackpropFilter (8.31m/8.31m flops)
  training/Adam/gradients/model_1/fire8/squeeze1x1/convolution_grad/Conv2DBackpropInput (8.31m/8.31m flops)
  model_1/fire7/squeeze1x1/convolution (6.23m/6.23m flops)
  training/Adam/gradients/model_1/fire7/squeeze1x1/convolution_grad/Conv2DBackpropFilter (6.23m/6.23m flops)
  training/Adam/gradients/model_1/fire7/squeeze1x1/convolution_grad/Conv2DBackpropInput (6.23m/6.23m flops)
  model_1/fire2/squeeze1x1/convolution (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/squeeze1x1/convolution_grad/Conv2DBackpropFilter (6.20m/6.20m flops)
  model_1/fire2/expand1x1/convolution (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/squeeze1x1/convolution_grad/Conv2DBackpropInput (6.20m/6.20m flops)
  model_1/fire3/expand1x1/convolution (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire3/expand1x1/convolution_grad/Conv2DBackpropInput (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/expand1x1/convolution_grad/Conv2DBackpropInput (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/expand1x1/convolution_grad/Conv2DBackpropFilter (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire3/expand1x1/convolution_grad/Conv2DBackpropFilter (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire4/expand1x1/convolution_grad/Conv2DBackpropInput (5.97m/5.97m flops)
  model_1/fire5/expand1x1/convolution (5.97m/5.97m flops)
  model_1/fire4/squeeze1x1/convolution (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire5/expand1x1/convolution_grad/Conv2DBackpropInput (5.97m/5.97m flops)
  model_1/fire4/expand1x1/convolution (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire5/expand1x1/convolution_grad/Conv2DBackpropFilter (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire4/squeeze1x1/convolution_grad/Conv2DBackpropInput (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire4/squeeze1x1/convolution_grad/Conv2DBackpropFilter (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire4/expand1x1/convolution_grad/Conv2DBackpropFilter (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire8/expand1x1/convolution_grad/Conv2DBackpropInput (5.54m/5.54m flops)
  training/Adam/gradients/model_1/fire9/expand1x1/convolution_grad/Conv2DBackpropFilter (5.54m/5.54m flops)
  training/Adam/gradients/model_1/fire9/expand1x1/convolution_grad/Conv2DBackpropInput (5.54m/5.54m flops)
  training/Adam/gradients/model_1/fire8/expand1x1/convolution_grad/Conv2DBackpropFilter (5.54m/5.54m flops)
  model_1/fire8/expand1x1/convolution (5.54m/5.54m flops)
  model_1/fire9/expand1x1/convolution (5.54m/5.54m flops)
  DetectionLayer/convolution (5.19m/5.19m flops)
  training/Adam/gradients/DetectionLayer/convolution_grad/Conv2DBackpropFilter (5.19m/5.19m flops)
  training/Adam/gradients/DetectionLayer/convolution_grad/Conv2DBackpropInput (5.19m/5.19m flops)
  model_1/fire6/squeeze1x1/convolution (4.15m/4.15m flops)
  training/Adam/gradients/model_1/fire6/squeeze1x1/convolution_grad/Conv2DBackpropInput (4.15m/4.15m flops)
  training/Adam/gradients/model_1/fire6/squeeze1x1/convolution_grad/Conv2DBackpropFilter (4.15m/4.15m flops)
  model_1/fire7/expand1x1/convolution (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire7/expand1x1/convolution_grad/Conv2DBackpropInput (3.12m/3.12m flops)
  model_1/fire6/expand1x1/convolution (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire7/expand1x1/convolution_grad/Conv2DBackpropFilter (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire6/expand1x1/convolution_grad/Conv2DBackpropInput (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire6/expand1x1/convolution_grad/Conv2DBackpropFilter (3.12m/3.12m flops)
  training/Adam/gradients/model_1/pool1/MaxPool_grad/MaxPoolGrad (1.94m/1.94m flops)
  model_1/pool1/MaxPool (1.74m/1.74m flops)
  training/Adam/gradients/model_1/pool3/MaxPool_grad/MaxPoolGrad (933.12k/933.12k flops)
  model_1/pool3/MaxPool (839.81k/839.81k flops)
  model_1/conv1/BiasAdd (788.54k/788.54k flops)
  training/Adam/gradients/model_1/conv1/BiasAdd_grad/BiasAddGrad (788.48k/788.48k flops)
  training/Adam/gradients/model_1/pool5/MaxPool_grad/MaxPoolGrad (432.64k/432.64k flops)
  model_1/pool5/MaxPool (389.38k/389.38k flops)
  fire9/expand3x3/random_uniform (147.46k/294.91k flops)
    fire9/expand3x3/random_uniform/mul (147.46k/147.46k flops)
    fire9/expand3x3/random_uniform/sub (1/1 flops)
  fire8/expand3x3/random_uniform (147.46k/294.91k flops)
    fire8/expand3x3/random_uniform/mul (147.46k/147.46k flops)
    fire8/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_49 (147.46k/294.91k flops)
    training/Adam/clip_by_value_49/Minimum (147.46k/147.46k flops)
  training/Adam/clip_by_value_43 (147.46k/294.91k flops)
    training/Adam/clip_by_value_43/Minimum (147.46k/147.46k flops)
  model_1/fire3/expand3x3/BiasAdd (193.60k/193.60k flops)
  model_1/fire2/expand1x1/BiasAdd (193.60k/193.60k flops)
  model_1/fire2/expand3x3/BiasAdd (193.60k/193.60k flops)
  model_1/fire3/expand1x1/BiasAdd (193.60k/193.60k flops)
  training/Adam/gradients/model_1/fire2/expand3x3/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  training/Adam/gradients/model_1/fire3/expand1x1/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  training/Adam/gradients/model_1/fire3/expand3x3/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  training/Adam/gradients/model_1/fire2/expand1x1/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  fire7/expand3x3/random_uniform (82.94k/165.89k flops)
    fire7/expand3x3/random_uniform/mul (82.94k/82.94k flops)
    fire7/expand3x3/random_uniform/sub (1/1 flops)
  fire6/expand3x3/random_uniform (82.94k/165.89k flops)
    fire6/expand3x3/random_uniform/mul (82.94k/82.94k flops)
    fire6/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_31 (82.94k/165.89k flops)
    training/Adam/clip_by_value_31/Minimum (82.94k/82.94k flops)
  training/Adam/clip_by_value_37 (82.94k/165.89k flops)
    training/Adam/clip_by_value_37/Minimum (82.94k/82.94k flops)
  training/Adam/add_129 (147.46k/147.46k flops)
  training/Adam/mul_241 (147.46k/147.46k flops)
  training/Adam/sub_148 (147.46k/147.46k flops)
  training/Adam/mul_242 (147.46k/147.46k flops)
  training/Adam/mul_211 (147.46k/147.46k flops)
  training/Adam/mul_212 (147.46k/147.46k flops)
  training/Adam/sub_130 (147.46k/147.46k flops)
  training/Adam/add_127 (147.46k/147.46k flops)
  training/Adam/truediv_49 (147.46k/147.46k flops)
  training/Adam/add_128 (147.46k/147.46k flops)
  training/Adam/truediv_43 (147.46k/147.46k flops)
  training/Adam/mul_215 (147.46k/147.46k flops)
  training/Adam/mul_214 (147.46k/147.46k flops)
  training/Adam/mul_213 (147.46k/147.46k flops)
  training/Adam/mul_244 (147.46k/147.46k flops)
  training/Adam/mul_245 (147.46k/147.46k flops)
  training/Adam/Square_48 (147.46k/147.46k flops)
  training/Adam/add_145 (147.46k/147.46k flops)
  training/Adam/add_146 (147.46k/147.46k flops)
  training/Adam/add_147 (147.46k/147.46k flops)
  training/Adam/mul_243 (147.46k/147.46k flops)
  training/Adam/Square_42 (147.46k/147.46k flops)
  model_1/fire5/expand1x1/BiasAdd (93.31k/93.31k flops)
  model_1/fire4/expand1x1/BiasAdd (93.31k/93.31k flops)
  model_1/fire4/expand3x3/BiasAdd (93.31k/93.31k flops)
  model_1/fire5/expand3x3/BiasAdd (93.31k/93.31k flops)
  training/Adam/gradients/model_1/fire5/expand3x3/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/gradients/model_1/fire4/expand1x1/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/gradients/model_1/fire5/expand1x1/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/gradients/model_1/fire4/expand3x3/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/sub_94 (82.94k/82.94k flops)
  training/Adam/add_109 (82.94k/82.94k flops)
  training/Adam/sub_112 (82.94k/82.94k flops)
  training/Adam/add_111 (82.94k/82.94k flops)
  training/Adam/add_110 (82.94k/82.94k flops)
  training/Adam/add_91 (82.94k/82.94k flops)
  training/Adam/mul_151 (82.94k/82.94k flops)
  training/Adam/mul_152 (82.94k/82.94k flops)
  training/Adam/mul_153 (82.94k/82.94k flops)
  training/Adam/mul_154 (82.94k/82.94k flops)
  training/Adam/mul_155 (82.94k/82.94k flops)
  training/Adam/Square_36 (82.94k/82.94k flops)
  training/Adam/Square_30 (82.94k/82.94k flops)
  training/Adam/mul_185 (82.94k/82.94k flops)
  training/Adam/mul_184 (82.94k/82.94k flops)
  training/Adam/mul_181 (82.94k/82.94k flops)
  training/Adam/mul_183 (82.94k/82.94k flops)
  training/Adam/mul_182 (82.94k/82.94k flops)
  training/Adam/truediv_37 (82.94k/82.94k flops)
  training/Adam/add_92 (82.94k/82.94k flops)
  training/Adam/truediv_31 (82.94k/82.94k flops)
  training/Adam/add_93 (82.94k/82.94k flops)
  fire5/expand3x3/random_uniform (36.86k/73.73k flops)
    fire5/expand3x3/random_uniform/mul (36.86k/36.86k flops)
    fire5/expand3x3/random_uniform/sub (1/1 flops)
  fire4/expand3x3/random_uniform (36.86k/73.73k flops)
    fire4/expand3x3/random_uniform/mul (36.86k/36.86k flops)
    fire4/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_19 (36.86k/73.73k flops)
    training/Adam/clip_by_value_19/Minimum (36.86k/36.86k flops)
  training/Adam/clip_by_value_25 (36.86k/73.73k flops)
    training/Adam/clip_by_value_25/Minimum (36.86k/36.86k flops)
  fire9/squeeze1x1/random_uniform (32.77k/65.54k flops)
    fire9/squeeze1x1/random_uniform/mul (32.77k/32.77k flops)
    fire9/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_45 (32.77k/65.54k flops)
    training/Adam/clip_by_value_45/Minimum (32.77k/32.77k flops)
  fire8/squeeze1x1/random_uniform (24.58k/49.15k flops)
    fire8/squeeze1x1/random_uniform/mul (24.58k/24.58k flops)
    fire8/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_39 (24.58k/49.15k flops)
    training/Adam/clip_by_value_39/Minimum (24.58k/24.58k flops)
  training/Adam/gradients/AddN_17 (48.40k/48.40k flops)
  training/Adam/gradients/AddN_16 (48.40k/48.40k flops)
  model_1/fire2/squeeze1x1/BiasAdd (48.40k/48.40k flops)
  model_1/fire3/squeeze1x1/BiasAdd (48.40k/48.40k flops)
  training/Adam/gradients/model_1/fire3/squeeze1x1/BiasAdd_grad/BiasAddGrad (48.38k/48.38k flops)
  training/Adam/gradients/model_1/fire2/squeeze1x1/BiasAdd_grad/BiasAddGrad (48.38k/48.38k flops)
  model_1/fire8/expand1x1/BiasAdd (43.26k/43.26k flops)
  model_1/fire8/expand3x3/BiasAdd (43.26k/43.26k flops)
  model_1/fire9/expand1x1/BiasAdd (43.26k/43.26k flops)
  model_1/fire9/expand3x3/BiasAdd (43.26k/43.26k flops)
  training/Adam/gradients/model_1/fire9/expand1x1/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  training/Adam/gradients/model_1/fire8/expand1x1/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  training/Adam/gradients/model_1/fire8/expand3x3/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  training/Adam/gradients/model_1/fire9/expand3x3/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  fire7/squeeze1x1/random_uniform (18.43k/36.87k flops)
    fire7/squeeze1x1/random_uniform/mul (18.43k/18.43k flops)
    fire7/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/add_73 (36.86k/36.86k flops)
  training/Adam/add_74 (36.86k/36.86k flops)
  training/Adam/add_75 (36.86k/36.86k flops)
  training/Adam/Square_24 (36.86k/36.86k flops)
  training/Adam/sub_58 (36.86k/36.86k flops)
  training/Adam/add_57 (36.86k/36.86k flops)
  training/Adam/mul_125 (36.86k/36.86k flops)
  training/Adam/Square_18 (36.86k/36.86k flops)
  training/Adam/mul_124 (36.86k/36.86k flops)
  training/Adam/add_55 (36.86k/36.86k flops)
  training/Adam/mul_122 (36.86k/36.86k flops)
  training/Adam/mul_121 (36.86k/36.86k flops)
  training/Adam/add_56 (36.86k/36.86k flops)
  training/Adam/mul_123 (36.86k/36.86k flops)
  training/Adam/truediv_19 (36.86k/36.86k flops)
  training/Adam/mul_91 (36.86k/36.86k flops)
  training/Adam/sub_76 (36.86k/36.86k flops)
  training/Adam/mul_92 (36.86k/36.86k flops)
  training/Adam/clip_by_value_33 (18.43k/36.86k flops)
    training/Adam/clip_by_value_33/Minimum (18.43k/18.43k flops)
  training/Adam/mul_93 (36.86k/36.86k flops)
  training/Adam/truediv_25 (36.86k/36.86k flops)
  training/Adam/mul_95 (36.86k/36.86k flops)
  training/Adam/mul_94 (36.86k/36.86k flops)
  fire8/expand1x1/random_uniform (16.38k/32.77k flops)
    fire8/expand1x1/random_uniform/mul (16.38k/16.38k flops)
    fire8/expand1x1/random_uniform/sub (1/1 flops)
  fire9/expand1x1/random_uniform (16.38k/32.77k flops)
    fire9/expand1x1/random_uniform/mul (16.38k/16.38k flops)
    fire9/expand1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_41 (16.38k/32.77k flops)
    training/Adam/clip_by_value_41/Minimum (16.38k/16.38k flops)
  training/Adam/add_135 (32.77k/32.77k flops)
  training/Adam/add_134 (32.77k/32.77k flops)
  training/Adam/add_133 (32.77k/32.77k flops)
  training/Adam/truediv_45 (32.77k/32.77k flops)
  training/Adam/Square_44 (32.77k/32.77k flops)
  training/Adam/clip_by_value_47 (16.38k/32.77k flops)
    training/Adam/clip_by_value_47/Minimum (16.38k/16.38k flops)
  training/Adam/mul_221 (32.77k/32.77k flops)
  training/Adam/mul_222 (32.77k/32.77k flops)
  training/Adam/mul_223 (32.77k/32.77k flops)
  training/Adam/mul_224 (32.77k/32.77k flops)
  training/Adam/mul_225 (32.77k/32.77k flops)
  training/Adam/sub_136 (32.77k/32.77k flops)
  model_1/fire7/expand1x1/BiasAdd (32.45k/32.45k flops)
  model_1/fire7/expand3x3/BiasAdd (32.45k/32.45k flops)
  model_1/fire6/expand3x3/BiasAdd (32.45k/32.45k flops)
  model_1/fire6/expand1x1/BiasAdd (32.45k/32.45k flops)
  training/Adam/gradients/model_1/fire6/expand3x3/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/gradients/model_1/fire6/expand1x1/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/gradients/model_1/fire7/expand3x3/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/gradients/model_1/fire7/expand1x1/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/clip_by_value_51 (15.36k/30.72k flops)
    training/Adam/clip_by_value_51/Minimum (15.36k/15.36k flops)
  DetectionLayer/truncated_normal (15.36k/30.72k flops)
    DetectionLayer/truncated_normal/mul (15.36k/15.36k flops)
  fire6/squeeze1x1/random_uniform (12.29k/24.58k flops)
    fire6/squeeze1x1/random_uniform/mul (12.29k/12.29k flops)
    fire6/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/mul_195 (24.58k/24.58k flops)
  training/Adam/add_116 (24.58k/24.58k flops)
  training/Adam/clip_by_value_27 (12.29k/24.58k flops)
    training/Adam/clip_by_value_27/Minimum (12.29k/12.29k flops)
  training/Adam/truediv_39 (24.58k/24.58k flops)
  training/Adam/add_115 (24.58k/24.58k flops)
  training/Adam/sub_118 (24.58k/24.58k flops)
  training/Adam/add_117 (24.58k/24.58k flops)
  training/Adam/mul_194 (24.58k/24.58k flops)
  training/Adam/mul_193 (24.58k/24.58k flops)
  training/Adam/Square_38 (24.58k/24.58k flops)
  training/Adam/mul_191 (24.58k/24.58k flops)
  training/Adam/mul_192 (24.58k/24.58k flops)
  model_1/fire5/squeeze1x1/BiasAdd (23.33k/23.33k flops)
  training/Adam/gradients/AddN_14 (23.33k/23.33k flops)
  training/Adam/gradients/AddN_15 (23.33k/23.33k flops)
  model_1/fire4/squeeze1x1/BiasAdd (23.33k/23.33k flops)
  training/Adam/gradients/model_1/fire5/squeeze1x1/BiasAdd_grad/BiasAddGrad (23.30k/23.30k flops)
  training/Adam/gradients/model_1/fire4/squeeze1x1/BiasAdd_grad/BiasAddGrad (23.30k/23.30k flops)
  fire7/expand1x1/random_uniform (9.22k/18.43k flops)
    fire7/expand1x1/random_uniform/mul (9.22k/9.22k flops)
    fire7/expand1x1/random_uniform/sub (1/1 flops)
  fire6/expand1x1/random_uniform (9.22k/18.43k flops)
    fire6/expand1x1/random_uniform/mul (9.22k/9.22k flops)
    fire6/expand1x1/random_uniform/sub (1/1 flops)
  fire3/expand3x3/random_uniform (9.22k/18.43k flops)
    fire3/expand3x3/random_uniform/mul (9.22k/9.22k flops)
    fire3/expand3x3/random_uniform/sub (1/1 flops)
  fire2/expand3x3/random_uniform (9.22k/18.43k flops)
    fire2/expand3x3/random_uniform/mul (9.22k/9.22k flops)
    fire2/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_7 (9.22k/18.43k flops)
    training/Adam/clip_by_value_7/Minimum (9.22k/9.22k flops)
  training/Adam/clip_by_value_29 (9.22k/18.43k flops)
    training/Adam/clip_by_value_29/Minimum (9.22k/9.22k flops)
  training/Adam/sub_100 (18.43k/18.43k flops)
  training/Adam/clip_by_value_13 (9.22k/18.43k flops)
    training/Adam/clip_by_value_13/Minimum (9.22k/9.22k flops)
  training/Adam/truediv_33 (18.43k/18.43k flops)
  training/Adam/add_99 (18.43k/18.43k flops)
  training/Adam/add_98 (18.43k/18.43k flops)
  training/Adam/add_97 (18.43k/18.43k flops)
  training/Adam/clip_by_value_35 (9.22k/18.43k flops)
    training/Adam/clip_by_value_35/Minimum (9.22k/9.22k flops)
  training/Adam/mul_162 (18.43k/18.43k flops)
  training/Adam/mul_165 (18.43k/18.43k flops)
  training/Adam/mul_164 (18.43k/18.43k flops)
  training/Adam/Square_32 (18.43k/18.43k flops)
  training/Adam/mul_163 (18.43k/18.43k flops)
  training/Adam/mul_161 (18.43k/18.43k flops)
  loss/lambda_1_loss/Maximum_3 (16.90k/16.90k flops)
  loss/lambda_1_loss/sub_6 (16.90k/16.90k flops)
  loss/lambda_1_loss/Maximum_2 (16.90k/16.90k flops)
  loss/lambda_1_loss/Minimum_1 (16.90k/16.90k flops)
  fire5/squeeze1x1/random_uniform (8.19k/16.39k flops)
    fire5/squeeze1x1/random_uniform/mul (8.19k/8.19k flops)
    fire5/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/mul_204 (16.38k/16.38k flops)
  training/Adam/mul_231 (16.38k/16.38k flops)
  training/Adam/mul_232 (16.38k/16.38k flops)
  training/Adam/mul_203 (16.38k/16.38k flops)
  training/Adam/mul_205 (16.38k/16.38k flops)
  training/Adam/Square_40 (16.38k/16.38k flops)
  training/Adam/add_141 (16.38k/16.38k flops)
  training/Adam/add_140 (16.38k/16.38k flops)
  training/Adam/mul_233 (16.38k/16.38k flops)
  training/Adam/add_139 (16.38k/16.38k flops)
  training/Adam/sub_142 (16.38k/16.38k flops)
  training/Adam/mul_234 (16.38k/16.38k flops)
  training/Adam/mul_235 (16.38k/16.38k flops)
  training/Adam/clip_by_value_21 (8.19k/16.38k flops)
    training/Adam/clip_by_value_21/Minimum (8.19k/8.19k flops)
  training/Adam/truediv_47 (16.38k/16.38k flops)
  training/Adam/truediv_41 (16.38k/16.38k flops)
  training/Adam/mul_202 (16.38k/16.38k flops)
  training/Adam/sub_124 (16.38k/16.38k flops)
  training/Adam/Square_46 (16.38k/16.38k flops)
  training/Adam/mul_201 (16.38k/16.38k flops)
  training/Adam/add_121 (16.38k/16.38k flops)
  training/Adam/add_123 (16.38k/16.38k flops)
  training/Adam/add_122 (16.38k/16.38k flops)
  training/Adam/truediv_51 (15.36k/15.36k flops)
  training/Adam/Square_50 (15.36k/15.36k flops)
  training/Adam/sub_154 (15.36k/15.36k flops)
  training/Adam/mul_254 (15.36k/15.36k flops)
  training/Adam/add_151 (15.36k/15.36k flops)
  training/Adam/add_152 (15.36k/15.36k flops)
  training/Adam/add_153 (15.36k/15.36k flops)
  training/Adam/mul_251 (15.36k/15.36k flops)
  training/Adam/mul_252 (15.36k/15.36k flops)
  training/Adam/mul_253 (15.36k/15.36k flops)
  training/Adam/mul_255 (15.36k/15.36k flops)
  training/Adam/gradients/AddN_9 (15.21k/15.21k flops)
  training/Adam/Square_26 (12.29k/12.29k flops)
  training/Adam/truediv_27 (12.29k/12.29k flops)
  training/Adam/mul_131 (12.29k/12.29k flops)
  training/Adam/add_79 (12.29k/12.29k flops)
  training/Adam/add_81 (12.29k/12.29k flops)
  training/Adam/mul_132 (12.29k/12.29k flops)
  training/Adam/mul_133 (12.29k/12.29k flops)
  training/Adam/mul_135 (12.29k/12.29k flops)
  training/Adam/add_80 (12.29k/12.29k flops)
  training/Adam/sub_82 (12.29k/12.29k flops)
  training/Adam/mul_134 (12.29k/12.29k flops)
  model_1/fire8/squeeze1x1/BiasAdd (10.82k/10.82k flops)
  training/Adam/gradients/AddN_10 (10.82k/10.82k flops)
  training/Adam/gradients/AddN_11 (10.82k/10.82k flops)
  model_1/fire9/squeeze1x1/BiasAdd (10.82k/10.82k flops)
  training/Adam/gradients/model_1/fire8/squeeze1x1/BiasAdd_grad/BiasAddGrad (10.75k/10.75k flops)
  training/Adam/gradients/model_1/fire9/squeeze1x1/BiasAdd_grad/BiasAddGrad (10.75k/10.75k flops)
  training/Adam/add_39 (9.22k/9.22k flops)
  training/Adam/add_38 (9.22k/9.22k flops)
  training/Adam/mul_33 (9.22k/9.22k flops)
  training/Adam/mul_32 (9.22k/9.22k flops)
  training/Adam/mul_175 (9.22k/9.22k flops)
  training/Adam/mul_31 (9.22k/9.22k flops)
  training/Adam/mul_65 (9.22k/9.22k flops)
  training/Adam/mul_174 (9.22k/9.22k flops)
  training/Adam/mul_34 (9.22k/9.22k flops)
  training/Adam/mul_171 (9.22k/9.22k flops)
  training/Adam/Square_12 (9.22k/9.22k flops)
  training/Adam/truediv_7 (9.22k/9.22k flops)
  training/Adam/mul_173 (9.22k/9.22k flops)
  training/Adam/mul_172 (9.22k/9.22k flops)
  training/Adam/mul_35 (9.22k/9.22k flops)
  training/Adam/Square_28 (9.22k/9.22k flops)
  training/Adam/Square_34 (9.22k/9.22k flops)
  training/Adam/add_105 (9.22k/9.22k flops)
  training/Adam/add_104 (9.22k/9.22k flops)
  training/Adam/add_87 (9.22k/9.22k flops)
  training/Adam/add_103 (9.22k/9.22k flops)
  training/Adam/sub_22 (9.22k/9.22k flops)
  training/Adam/add_86 (9.22k/9.22k flops)
  training/Adam/add_85 (9.22k/9.22k flops)
  training/Adam/mul_64 (9.22k/9.22k flops)
  training/Adam/mul_63 (9.22k/9.22k flops)
  training/Adam/sub_88 (9.22k/9.22k flops)
  training/Adam/sub_106 (9.22k/9.22k flops)
  training/Adam/mul_141 (9.22k/9.22k flops)
  training/Adam/truediv_13 (9.22k/9.22k flops)
  training/Adam/Square_6 (9.22k/9.22k flops)
  training/Adam/mul_62 (9.22k/9.22k flops)
  training/Adam/mul_143 (9.22k/9.22k flops)
  training/Adam/add_37 (9.22k/9.22k flops)
  training/Adam/mul_145 (9.22k/9.22k flops)
  training/Adam/truediv_35 (9.22k/9.22k flops)
  training/Adam/sub_40 (9.22k/9.22k flops)
  training/Adam/mul_144 (9.22k/9.22k flops)
  training/Adam/add_21 (9.22k/9.22k flops)
  training/Adam/add_20 (9.22k/9.22k flops)
  training/Adam/mul_142 (9.22k/9.22k flops)
  training/Adam/add_19 (9.22k/9.22k flops)
  training/Adam/truediv_29 (9.22k/9.22k flops)
  training/Adam/mul_61 (9.22k/9.22k flops)
  loss/lambda_1_loss/add_6 (8.45k/8.45k flops)
  loss/lambda_1_loss/truediv_1 (8.45k/8.45k flops)
  loss/lambda_1_loss/sub_7 (8.45k/8.45k flops)
  loss/lambda_1_loss/mul_6 (8.45k/8.45k flops)
  fire4/expand1x1/random_uniform (4.10k/8.19k flops)
    fire4/expand1x1/random_uniform/mul (4.10k/4.10k flops)
    fire4/expand1x1/random_uniform/sub (1/1 flops)
  fire5/expand1x1/random_uniform (4.10k/8.19k flops)
    fire5/expand1x1/random_uniform/mul (4.10k/4.10k flops)
    fire5/expand1x1/random_uniform/sub (1/1 flops)
  fire4/squeeze1x1/random_uniform (4.10k/8.19k flops)
    fire4/squeeze1x1/random_uniform/mul (4.10k/4.10k flops)
    fire4/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/Square_20 (8.19k/8.19k flops)
  training/Adam/truediv_21 (8.19k/8.19k flops)
  training/Adam/mul_103 (8.19k/8.19k flops)
  training/Adam/mul_102 (8.19k/8.19k flops)
  training/Adam/mul_101 (8.19k/8.19k flops)
  training/Adam/sub_64 (8.19k/8.19k flops)
  training/Adam/add_63 (8.19k/8.19k flops)
  training/Adam/clip_by_value_17 (4.10k/8.19k flops)
    training/Adam/clip_by_value_17/Minimum (4.10k/4.10k flops)
  training/Adam/clip_by_value_15 (4.10k/8.19k flops)
    training/Adam/clip_by_value_15/Minimum (4.10k/4.10k flops)
  training/Adam/mul_104 (8.19k/8.19k flops)
  training/Adam/mul_105 (8.19k/8.19k flops)
  training/Adam/clip_by_value_23 (4.10k/8.19k flops)
    training/Adam/clip_by_value_23/Minimum (4.10k/4.10k flops)
  training/Adam/add_61 (8.19k/8.19k flops)
  training/Adam/add_62 (8.19k/8.19k flops)
  model_1/fire6/squeeze1x1/BiasAdd (8.11k/8.11k flops)
  model_1/fire7/squeeze1x1/BiasAdd (8.11k/8.11k flops)
  training/Adam/gradients/AddN_12 (8.11k/8.11k flops)
  training/Adam/gradients/AddN_13 (8.11k/8.11k flops)
  training/Adam/gradients/model_1/fire7/squeeze1x1/BiasAdd_grad/BiasAddGrad (8.06k/8.06k flops)
  training/Adam/gradients/model_1/fire6/squeeze1x1/BiasAdd_grad/BiasAddGrad (8.06k/8.06k flops)
  training/Adam/gradients/AddN_8 (5.07k/5.07k flops)
  DetectionLayer/BiasAdd (5.07k/5.07k flops)
  training/Adam/gradients/DetectionLayer/BiasAdd_grad/BiasAddGrad (5.04k/5.04k flops)
  fire3/squeeze1x1/random_uniform (2.05k/4.10k flops)
    fire3/squeeze1x1/random_uniform/mul (2.05k/2.05k flops)
    fire3/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_9 (2.05k/4.10k flops)
    training/Adam/clip_by_value_9/Minimum (2.05k/2.05k flops)
  training/Adam/mul_73 (4.10k/4.10k flops)
  training/Adam/mul_85 (4.10k/4.10k flops)
  training/Adam/mul_112 (4.10k/4.10k flops)
  training/Adam/mul_113 (4.10k/4.10k flops)
  training/Adam/mul_114 (4.10k/4.10k flops)
  training/Adam/mul_115 (4.10k/4.10k flops)
  training/Adam/Square_22 (4.10k/4.10k flops)
  training/Adam/Square_16 (4.10k/4.10k flops)
  training/Adam/Square_14 (4.10k/4.10k flops)
  training/Adam/sub_52 (4.10k/4.10k flops)
  training/Adam/sub_46 (4.10k/4.10k flops)
  training/Adam/add_69 (4.10k/4.10k flops)
  training/Adam/mul_84 (4.10k/4.10k flops)
  training/Adam/mul_83 (4.10k/4.10k flops)
  training/Adam/mul_82 (4.10k/4.10k flops)
  training/Adam/mul_81 (4.10k/4.10k flops)
  training/Adam/mul_75 (4.10k/4.10k flops)
  training/Adam/mul_71 (4.10k/4.10k flops)
  training/Adam/mul_72 (4.10k/4.10k flops)
  training/Adam/mul_74 (4.10k/4.10k flops)
  training/Adam/sub_70 (4.10k/4.10k flops)
  training/Adam/add_68 (4.10k/4.10k flops)
  training/Adam/add_67 (4.10k/4.10k flops)
  training/Adam/add_51 (4.10k/4.10k flops)
  training/Adam/add_50 (4.10k/4.10k flops)
  training/Adam/add_49 (4.10k/4.10k flops)
  training/Adam/add_45 (4.10k/4.10k flops)
  training/Adam/add_43 (4.10k/4.10k flops)
  training/Adam/add_44 (4.10k/4.10k flops)
  training/Adam/truediv_23 (4.10k/4.10k flops)
  training/Adam/truediv_17 (4.10k/4.10k flops)
  training/Adam/truediv_15 (4.10k/4.10k flops)
  training/Adam/mul_111 (4.10k/4.10k flops)
  conv1/random_uniform (1.73k/3.46k flops)
    conv1/random_uniform/mul (1.73k/1.73k flops)
    conv1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_1 (1.73k/3.46k flops)
    training/Adam/clip_by_value_1/Minimum (1.73k/1.73k flops)
  training/Adam/gradients/AddN_7 (3.38k/3.38k flops)
  fire2/expand1x1/random_uniform (1.02k/2.05k flops)
    fire2/expand1x1/random_uniform/mul (1.02k/1.02k flops)
    fire2/expand1x1/random_uniform/sub (1/1 flops)
  fire3/expand1x1/random_uniform (1.02k/2.05k flops)
    fire3/expand1x1/random_uniform/mul (1.02k/1.02k flops)
    fire3/expand1x1/random_uniform/sub (1/1 flops)
  fire2/squeeze1x1/random_uniform (1.02k/2.05k flops)
    fire2/squeeze1x1/random_uniform/mul (1.02k/1.02k flops)
    fire2/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/truediv_9 (2.05k/2.05k flops)
  training/Adam/mul_45 (2.05k/2.05k flops)
  training/Adam/mul_44 (2.05k/2.05k flops)
  training/Adam/mul_43 (2.05k/2.05k flops)
  training/Adam/clip_by_value_5 (1.02k/2.05k flops)
    training/Adam/clip_by_value_5/Minimum (1.02k/1.02k flops)
  training/Adam/mul_42 (2.05k/2.05k flops)
  training/Adam/mul_41 (2.05k/2.05k flops)
  training/Adam/sub_28 (2.05k/2.05k flops)
  training/Adam/Square_8 (2.05k/2.05k flops)
  training/Adam/clip_by_value_11 (1.02k/2.05k flops)
    training/Adam/clip_by_value_11/Minimum (1.02k/1.02k flops)
  training/Adam/add_27 (2.05k/2.05k flops)
  training/Adam/add_26 (2.05k/2.05k flops)
  training/Adam/add_25 (2.05k/2.05k flops)
  training/Adam/clip_by_value_3 (1.02k/2.05k flops)
    training/Adam/clip_by_value_3/Minimum (1.02k/1.02k flops)
  training/Adam/Square (1.73k/1.73k flops)
  training/Adam/add_1 (1.73k/1.73k flops)
  training/Adam/sub_4 (1.73k/1.73k flops)
  training/Adam/mul_1 (1.73k/1.73k flops)
  training/Adam/add_2 (1.73k/1.73k flops)
  training/Adam/truediv_1 (1.73k/1.73k flops)
  training/Adam/mul_2 (1.73k/1.73k flops)
  training/Adam/mul_3 (1.73k/1.73k flops)
  training/Adam/mul_4 (1.73k/1.73k flops)
  training/Adam/mul_5 (1.73k/1.73k flops)
  training/Adam/add_3 (1.73k/1.73k flops)
  loss/lambda_1_loss/cond/add_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Exp_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/add_5 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Minimum_grad/LessEqual (1.69k/1.69k flops)
  loss/lambda_1_loss/mul (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_1_grad/mul (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_1_grad/mul_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_5 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_grad/mul (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_grad/mul_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_9 (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/add (1.69k/1.69k flops)
  loss/lambda_1_loss/mul_15 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/div_1_grad/Neg (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/div_1_grad/RealDiv (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/add_2 (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/mul_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/mul_2 (1.69k/1.69k flops)
  loss/lambda_1_loss/mul_14 (1.69k/1.69k flops)
  loss/lambda_1_loss/div (1.69k/1.69k flops)
  loss/lambda_1_loss/div_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/div_3 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Maximum_grad/GreaterEqual (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_9_grad/Neg (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_2_grad/Neg (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_1_grad/Neg (1.69k/1.69k flops)
  loss/lambda_1_loss/Maximum (1.69k/1.69k flops)
  loss/lambda_1_loss/Maximum_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_10_grad/Neg (1.69k/1.69k flops)
  loss/lambda_1_loss/Minimum (1.69k/1.69k flops)
  loss/lambda_1_loss/Square (1.69k/1.69k flops)
  loss/lambda_1_loss/Square_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/sub (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_10 (1.69k/1.69k flops)
  loss/lambda_1_loss/add (1.69k/1.69k flops)
  loss/lambda_1_loss/add_2 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Maximum_1_grad/GreaterEqual (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_14_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/add_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_15_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_2 (1.69k/1.69k flops)
  training/Adam/gradients/AddN_6 (1.69k/1.69k flops)
  training/Adam/gradients/AddN_5 (1.69k/1.69k flops)
  loss/lambda_1_loss/Sum_3 (1.69k/1.69k flops)
  loss/lambda_1_loss/Sum_4 (1.69k/1.69k flops)
  training/Adam/add_8 (1.02k/1.02k flops)
  training/Adam/mul_21 (1.02k/1.02k flops)
  training/Adam/mul_25 (1.02k/1.02k flops)
  training/Adam/mul_24 (1.02k/1.02k flops)
  training/Adam/mul_22 (1.02k/1.02k flops)
  training/Adam/mul_23 (1.02k/1.02k flops)
  training/Adam/add_33 (1.02k/1.02k flops)
  training/Adam/add_9 (1.02k/1.02k flops)
  training/Adam/add_7 (1.02k/1.02k flops)
  training/Adam/truediv_5 (1.02k/1.02k flops)
  training/Adam/add_32 (1.02k/1.02k flops)
  training/Adam/add_31 (1.02k/1.02k flops)
  training/Adam/truediv_3 (1.02k/1.02k flops)
  training/Adam/truediv_11 (1.02k/1.02k flops)
  training/Adam/add_15 (1.02k/1.02k flops)
  training/Adam/add_14 (1.02k/1.02k flops)
  training/Adam/add_13 (1.02k/1.02k flops)
  training/Adam/mul_11 (1.02k/1.02k flops)
  training/Adam/mul_12 (1.02k/1.02k flops)
  training/Adam/mul_13 (1.02k/1.02k flops)
  training/Adam/sub_34 (1.02k/1.02k flops)
  training/Adam/sub_16 (1.02k/1.02k flops)
  training/Adam/mul_15 (1.02k/1.02k flops)
  training/Adam/Square_10 (1.02k/1.02k flops)
  training/Adam/mul_51 (1.02k/1.02k flops)
  training/Adam/mul_52 (1.02k/1.02k flops)
  training/Adam/mul_53 (1.02k/1.02k flops)
  training/Adam/mul_54 (1.02k/1.02k flops)
  training/Adam/mul_55 (1.02k/1.02k flops)
  training/Adam/sub_10 (1.02k/1.02k flops)
  training/Adam/Square_2 (1.02k/1.02k flops)
  training/Adam/Square_4 (1.02k/1.02k flops)
  training/Adam/mul_14 (1.02k/1.02k flops)
  loss/lambda_1_loss/sub_11 (845/845 flops)
  loss/lambda_1_loss/truediv (845/845 flops)
  loss/lambda_1_loss/sub_8 (845/845 flops)
  loss/lambda_1_loss/sub_3 (845/845 flops)
  loss/lambda_1_loss/mul_9 (845/845 flops)
  loss/lambda_1_loss/mul_12 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/RealDiv_2 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/RealDiv_1 (845/845 flops)
  training/Adam/gradients/AddN_4 (845/845 flops)
  loss/lambda_1_loss/mul_11 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/RealDiv (845/845 flops)
  loss/lambda_1_loss/mul_1 (845/845 flops)
  loss/lambda_1_loss/add_8 (845/845 flops)
  loss/lambda_1_loss/add_7 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_2_grad/mul_1 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_2_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul (845/845 flops)
  loss/lambda_1_loss/add_3 (845/845 flops)
  loss/lambda_1_loss/mul_10 (845/845 flops)
  loss/lambda_1_loss/Square_2 (845/845 flops)
  loss/lambda_1_loss/Less_1 (845/845 flops)
  loss/lambda_1_loss/Less (845/845 flops)
  loss/lambda_1_loss/Greater_4 (845/845 flops)
  loss/lambda_1_loss/Greater_3 (845/845 flops)
  loss/lambda_1_loss/Greater_2 (845/845 flops)
  loss/lambda_1_loss/Greater_1 (845/845 flops)
  loss/lambda_1_loss/Greater (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_1_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_3_grad/mul_1 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_3_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_4_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_11_grad/Neg (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_3_grad/Neg (845/845 flops)
  loss/lambda_1_loss/mul_5 (845/845 flops)
  loss/lambda_1_loss/mul_13 (845/845 flops)
  loss/lambda_1_loss/mul_8 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_1_grad/mul_1 (845/845 flops)
  loss/lambda_1_loss/mul_4 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_17_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_16_grad/mul (845/845 flops)
  loss/lambda_1_loss/mul_3 (845/845 flops)
  loss/lambda_1_loss/mul_2 (845/845 flops)
  loss/lambda_1_loss/mul_18 (845/845 flops)
  loss/lambda_1_loss/mul_17 (845/845 flops)
  loss/lambda_1_loss/mul_16 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/Neg (845/845 flops)
  loss/lambda_1_loss/Sum_6 (844/844 flops)
  loss/lambda_1_loss/Sum (844/844 flops)
  loss/lambda_1_loss/Sum_1 (844/844 flops)
  loss/lambda_1_loss/Sum_2 (844/844 flops)
  loss/lambda_1_loss/Sum_5 (844/844 flops)
  loss/lambda_1_loss/Sum_8 (844/844 flops)
  training/Adam/clip_by_value_44 (256/512 flops)
    training/Adam/clip_by_value_44/Minimum (256/256 flops)
  training/Adam/clip_by_value_42 (256/512 flops)
    training/Adam/clip_by_value_42/Minimum (256/256 flops)
  training/Adam/clip_by_value_48 (256/512 flops)
    training/Adam/clip_by_value_48/Minimum (256/256 flops)
  training/Adam/clip_by_value_50 (256/512 flops)
    training/Adam/clip_by_value_50/Minimum (256/256 flops)
  training/Adam/clip_by_value_30 (192/384 flops)
    training/Adam/clip_by_value_30/Minimum (192/192 flops)
  training/Adam/clip_by_value_38 (192/384 flops)
    training/Adam/clip_by_value_38/Minimum (192/192 flops)
  training/Adam/clip_by_value_36 (192/384 flops)
    training/Adam/clip_by_value_36/Minimum (192/192 flops)
  training/Adam/clip_by_value_32 (192/384 flops)
    training/Adam/clip_by_value_32/Minimum (192/192 flops)
  training/Adam/mul_208 (256/256 flops)
  training/Adam/mul_216 (256/256 flops)
  training/Adam/mul_207 (256/256 flops)
  training/Adam/mul_206 (256/256 flops)
  training/Adam/sub_127 (256/256 flops)
  training/Adam/sub_133 (256/256 flops)
  training/Adam/Square_41 (256/256 flops)
  training/Adam/Square_43 (256/256 flops)
  training/Adam/sub_151 (256/256 flops)
  training/Adam/Square_47 (256/256 flops)
  training/Adam/Square_49 (256/256 flops)
  training/Adam/clip_by_value_18 (128/256 flops)
    training/Adam/clip_by_value_18/Minimum (128/128 flops)
  training/Adam/clip_by_value_20 (128/256 flops)
    training/Adam/clip_by_value_20/Minimum (128/128 flops)
  training/Adam/clip_by_value_24 (128/256 flops)
    training/Adam/clip_by_value_24/Minimum (128/128 flops)
  training/Adam/clip_by_value_26 (128/256 flops)
    training/Adam/clip_by_value_26/Minimum (128/128 flops)
  training/Adam/add_124 (256/256 flops)
  training/Adam/mul_249 (256/256 flops)
  training/Adam/mul_238 (256/256 flops)
  training/Adam/mul_237 (256/256 flops)
  training/Adam/mul_236 (256/256 flops)
  training/Adam/mul_239 (256/256 flops)
  training/Adam/mul_240 (256/256 flops)
  training/Adam/mul_246 (256/256 flops)
  training/Adam/mul_247 (256/256 flops)
  training/Adam/mul_248 (256/256 flops)
  training/Adam/mul_209 (256/256 flops)
  training/Adam/mul_250 (256/256 flops)
  training/Adam/mul_220 (256/256 flops)
  training/Adam/mul_219 (256/256 flops)
  training/Adam/mul_218 (256/256 flops)
  training/Adam/mul_217 (256/256 flops)
  training/Adam/sub_145 (256/256 flops)
  training/Adam/mul_210 (256/256 flops)
  training/Adam/add_143 (256/256 flops)
  training/Adam/add_132 (256/256 flops)
  training/Adam/add_150 (256/256 flops)
  training/Adam/add_126 (256/256 flops)
  training/Adam/add_149 (256/256 flops)
  training/Adam/add_148 (256/256 flops)
  training/Adam/add_144 (256/256 flops)
  training/Adam/add_142 (256/256 flops)
  training/Adam/add_125 (256/256 flops)
  training/Adam/add_131 (256/256 flops)
  training/Adam/add_130 (256/256 flops)
  training/Adam/truediv_42 (256/256 flops)
  training/Adam/truediv_44 (256/256 flops)
  training/Adam/truediv_48 (256/256 flops)
  training/Adam/truediv_50 (256/256 flops)
  training/Adam/mul_180 (192/192 flops)
  training/Adam/mul_188 (192/192 flops)
  training/Adam/mul_186 (192/192 flops)
  training/Adam/mul_146 (192/192 flops)
  training/Adam/mul_147 (192/192 flops)
  training/Adam/mul_187 (192/192 flops)
  training/Adam/mul_148 (192/192 flops)
  training/Adam/mul_190 (192/192 flops)
  training/Adam/mul_149 (192/192 flops)
  training/Adam/mul_150 (192/192 flops)
  training/Adam/mul_179 (192/192 flops)
  training/Adam/mul_178 (192/192 flops)
  training/Adam/mul_177 (192/192 flops)
  training/Adam/mul_176 (192/192 flops)
  training/Adam/mul_156 (192/192 flops)
  training/Adam/mul_157 (192/192 flops)
  training/Adam/mul_158 (192/192 flops)
  training/Adam/mul_159 (192/192 flops)
  training/Adam/mul_160 (192/192 flops)
  training/Adam/Square_37 (192/192 flops)
  training/Adam/Square_35 (192/192 flops)
  training/Adam/Square_31 (192/192 flops)
  training/Adam/sub_115 (192/192 flops)
  training/Adam/sub_109 (192/192 flops)
  training/Adam/Square_29 (192/192 flops)
  training/Adam/add_114 (192/192 flops)
  training/Adam/add_112 (192/192 flops)
  training/Adam/add_94 (192/192 flops)
  training/Adam/add_108 (192/192 flops)
  training/Adam/add_90 (192/192 flops)
  training/Adam/add_89 (192/192 flops)
  training/Adam/truediv_38 (192/192 flops)
  training/Adam/add_88 (192/192 flops)
  training/Adam/truediv_36 (192/192 flops)
  training/Adam/add_113 (192/192 flops)
  training/Adam/truediv_32 (192/192 flops)
  training/Adam/add_107 (192/192 flops)
  training/Adam/add_106 (192/192 flops)
  training/Adam/truediv_30 (192/192 flops)
  training/Adam/add_95 (192/192 flops)
  training/Adam/add_96 (192/192 flops)
  training/Adam/sub_91 (192/192 flops)
  training/Adam/sub_97 (192/192 flops)
  training/Adam/mul_189 (192/192 flops)
  training/Adam/mul_90 (128/128 flops)
  training/Adam/mul_89 (128/128 flops)
  training/Adam/clip_by_value_46 (64/128 flops)
    training/Adam/clip_by_value_46/Minimum (64/64 flops)
  training/Adam/Square_23 (128/128 flops)
  training/Adam/Square_25 (128/128 flops)
  training/Adam/clip_by_value_40 (64/128 flops)
    training/Adam/clip_by_value_40/Minimum (64/64 flops)
  training/Adam/mul_88 (128/128 flops)
  training/Adam/add_78 (128/128 flops)
  training/Adam/add_77 (128/128 flops)
  training/Adam/add_76 (128/128 flops)
  training/Adam/add_72 (128/128 flops)
  training/Adam/add_71 (128/128 flops)
  training/Adam/mul_87 (128/128 flops)
  training/Adam/Square_19 (128/128 flops)
  training/Adam/Square_17 (128/128 flops)
  training/Adam/mul_86 (128/128 flops)
  training/Adam/add_70 (128/128 flops)
  training/Adam/truediv_18 (128/128 flops)
  training/Adam/mul_119 (128/128 flops)
  training/Adam/truediv_20 (128/128 flops)
  training/Adam/sub_61 (128/128 flops)
  training/Adam/clip_by_value_2 (64/128 flops)
    training/Adam/clip_by_value_2/Minimum (64/64 flops)
  training/Adam/add_53 (128/128 flops)
  training/Adam/sub_79 (128/128 flops)
  training/Adam/mul_116 (128/128 flops)
  training/Adam/add_59 (128/128 flops)
  training/Adam/mul_117 (128/128 flops)
  training/Adam/mul_118 (128/128 flops)
  training/Adam/mul_97 (128/128 flops)
  training/Adam/add_54 (128/128 flops)
  training/Adam/mul_120 (128/128 flops)
  training/Adam/mul_130 (128/128 flops)
  training/Adam/add_58 (128/128 flops)
  training/Adam/mul_129 (128/128 flops)
  training/Adam/mul_128 (128/128 flops)
  training/Adam/mul_127 (128/128 flops)
  training/Adam/mul_126 (128/128 flops)
  training/Adam/sub_73 (128/128 flops)
  training/Adam/add_60 (128/128 flops)
  training/Adam/mul_100 (128/128 flops)
  training/Adam/truediv_26 (128/128 flops)
  training/Adam/truediv_24 (128/128 flops)
  training/Adam/clip_by_value_8 (64/128 flops)
    training/Adam/clip_by_value_8/Minimum (64/64 flops)
  training/Adam/sub_55 (128/128 flops)
  training/Adam/add_52 (128/128 flops)
  training/Adam/clip_by_value_12 (64/128 flops)
    training/Adam/clip_by_value_12/Minimum (64/64 flops)
  training/Adam/clip_by_value_6 (64/128 flops)
    training/Adam/clip_by_value_6/Minimum (64/64 flops)
  training/Adam/mul_99 (128/128 flops)
  training/Adam/mul_98 (128/128 flops)
  training/Adam/clip_by_value_14 (64/128 flops)
    training/Adam/clip_by_value_14/Minimum (64/64 flops)
  training/Adam/mul_96 (128/128 flops)
  training/Adam/clip_by_value_28 (48/96 flops)
    training/Adam/clip_by_value_28/Minimum (48/48 flops)
  training/Adam/clip_by_value_34 (48/96 flops)
    training/Adam/clip_by_value_34/Minimum (48/48 flops)
  training/Adam/truediv_6 (64/64 flops)
  training/Adam/truediv_14 (64/64 flops)
  training/Adam/truediv_8 (64/64 flops)
  training/Adam/mul_30 (64/64 flops)
  training/Adam/mul_36 (64/64 flops)
  training/Adam/clip_by_value_22 (32/64 flops)
    training/Adam/clip_by_value_22/Minimum (32/32 flops)
  training/Adam/truediv_46 (64/64 flops)
  training/Adam/truediv_12 (64/64 flops)
  training/Adam/truediv_2 (64/64 flops)
  training/Adam/mul_29 (64/64 flops)
  training/Adam/mul_28 (64/64 flops)
  training/Adam/mul_27 (64/64 flops)
  training/Adam/truediv_40 (64/64 flops)
  training/Adam/mul_26 (64/64 flops)
  training/Adam/mul_68 (64/64 flops)
  training/Adam/mul_9 (64/64 flops)
  training/Adam/sub_121 (64/64 flops)
  training/Adam/sub_139 (64/64 flops)
  training/Adam/add_35 (64/64 flops)
  training/Adam/sub_19 (64/64 flops)
  training/Adam/sub_25 (64/64 flops)
  training/Adam/sub_37 (64/64 flops)
  training/Adam/mul_8 (64/64 flops)
  training/Adam/clip_by_value_16 (32/64 flops)
    training/Adam/clip_by_value_16/Minimum (32/32 flops)
  training/Adam/sub_43 (64/64 flops)
  training/Adam/mul_70 (64/64 flops)
  training/Adam/mul_7 (64/64 flops)
  training/Adam/mul_69 (64/64 flops)
  training/Adam/mul_37 (64/64 flops)
  training/Adam/mul_67 (64/64 flops)
  training/Adam/mul_66 (64/64 flops)
  training/Adam/mul_60 (64/64 flops)
  training/Adam/mul_6 (64/64 flops)
  training/Adam/mul_59 (64/64 flops)
  training/Adam/mul_58 (64/64 flops)
  training/Adam/mul_57 (64/64 flops)
  training/Adam/mul_56 (64/64 flops)
  training/Adam/mul_40 (64/64 flops)
  training/Adam/mul_39 (64/64 flops)
  training/Adam/sub_7 (64/64 flops)
  training/Adam/mul_38 (64/64 flops)
  training/Adam/Square_39 (64/64 flops)
  training/Adam/mul_227 (64/64 flops)
  training/Adam/mul_226 (64/64 flops)
  training/Adam/add_18 (64/64 flops)
  training/Adam/add_17 (64/64 flops)
  training/Adam/add_16 (64/64 flops)
  training/Adam/Square_7 (64/64 flops)
  training/Adam/add_138 (64/64 flops)
  training/Adam/add_137 (64/64 flops)
  training/Adam/add_136 (64/64 flops)
  training/Adam/mul_200 (64/64 flops)
  training/Adam/mul_199 (64/64 flops)
  training/Adam/mul_198 (64/64 flops)
  training/Adam/add_5 (64/64 flops)
  training/Adam/mul_197 (64/64 flops)
  training/Adam/mul_196 (64/64 flops)
  training/Adam/mul_10 (64/64 flops)
  training/Adam/Square_1 (64/64 flops)
  training/Adam/Square_11 (64/64 flops)
  training/Adam/add_120 (64/64 flops)
  training/Adam/add_119 (64/64 flops)
  training/Adam/Square_13 (64/64 flops)
  training/Adam/add_118 (64/64 flops)
  training/Adam/Square_5 (64/64 flops)
  training/Adam/add_6 (64/64 flops)
  training/Adam/Square_45 (64/64 flops)
  training/Adam/add_4 (64/64 flops)
  training/Adam/add_34 (64/64 flops)
  training/Adam/mul_229 (64/64 flops)
  training/Adam/add_22 (64/64 flops)
  training/Adam/mul_230 (64/64 flops)
  training/Adam/add_40 (64/64 flops)
  training/Adam/add_23 (64/64 flops)
  training/Adam/add_36 (64/64 flops)
  training/Adam/mul_228 (64/64 flops)
  training/Adam/add_41 (64/64 flops)
  training/Adam/add_42 (64/64 flops)
  training/Adam/add_24 (64/64 flops)
  training/Adam/clip_by_value_52 (30/60 flops)
    training/Adam/clip_by_value_52/Minimum (30/30 flops)
  training/Adam/truediv_28 (48/48 flops)
  training/Adam/add_101 (48/48 flops)
  training/Adam/mul_138 (48/48 flops)
  training/Adam/sub_103 (48/48 flops)
  training/Adam/mul_140 (48/48 flops)
  training/Adam/add_100 (48/48 flops)
  training/Adam/mul_166 (48/48 flops)
  training/Adam/sub_85 (48/48 flops)
  training/Adam/mul_139 (48/48 flops)
  training/Adam/mul_137 (48/48 flops)
  training/Adam/mul_168 (48/48 flops)
  training/Adam/mul_169 (48/48 flops)
  training/Adam/add_84 (48/48 flops)
  training/Adam/add_102 (48/48 flops)
  training/Adam/mul_167 (48/48 flops)
  training/Adam/add_83 (48/48 flops)
  training/Adam/add_82 (48/48 flops)
  training/Adam/Square_33 (48/48 flops)
  training/Adam/mul_136 (48/48 flops)
  training/Adam/truediv_34 (48/48 flops)
  training/Adam/mul_170 (48/48 flops)
  training/Adam/Square_27 (48/48 flops)
  training/Adam/sub_67 (32/32 flops)
  training/Adam/mul_79 (32/32 flops)
  training/Adam/truediv_16 (32/32 flops)
  training/Adam/add_64 (32/32 flops)
  training/Adam/Square_15 (32/32 flops)
  training/Adam/add_66 (32/32 flops)
  training/Adam/Square_21 (32/32 flops)
  training/Adam/mul_107 (32/32 flops)
  training/Adam/mul_106 (32/32 flops)
  training/Adam/mul_108 (32/32 flops)
  training/Adam/mul_80 (32/32 flops)
  training/Adam/mul_76 (32/32 flops)
  training/Adam/mul_77 (32/32 flops)
  training/Adam/mul_78 (32/32 flops)
  training/Adam/sub_49 (32/32 flops)
  training/Adam/add_47 (32/32 flops)
  training/Adam/add_48 (32/32 flops)
  training/Adam/add_65 (32/32 flops)
  training/Adam/mul_110 (32/32 flops)
  training/Adam/clip_by_value_10 (16/32 flops)
    training/Adam/clip_by_value_10/Minimum (16/16 flops)
  training/Adam/truediv_22 (32/32 flops)
  training/Adam/clip_by_value_4 (16/32 flops)
    training/Adam/clip_by_value_4/Minimum (16/16 flops)
  training/Adam/add_46 (32/32 flops)
  training/Adam/mul_109 (32/32 flops)
  training/Adam/mul_258 (30/30 flops)
  training/Adam/sub_157 (30/30 flops)
  training/Adam/mul_257 (30/30 flops)
  training/Adam/mul_259 (30/30 flops)
  training/Adam/add_156 (30/30 flops)
  training/Adam/add_155 (30/30 flops)
  training/Adam/add_154 (30/30 flops)
  training/Adam/mul_260 (30/30 flops)
  training/Adam/mul_256 (30/30 flops)
  training/Adam/truediv_52 (30/30 flops)
  training/Adam/Square_51 (30/30 flops)
  loss/lambda_1_loss/sub_4 (20/20 flops)
  loss/lambda_1_loss/add_4 (20/20 flops)
  loss/lambda_1_loss/div_2 (20/20 flops)
  training/Adam/add_10 (16/16 flops)
  training/Adam/add_11 (16/16 flops)
  training/Adam/mul_16 (16/16 flops)
  training/Adam/Square_3 (16/16 flops)
  training/Adam/add_30 (16/16 flops)
  training/Adam/add_29 (16/16 flops)
  training/Adam/mul_46 (16/16 flops)
  training/Adam/mul_47 (16/16 flops)
  training/Adam/mul_48 (16/16 flops)
  training/Adam/mul_49 (16/16 flops)
  training/Adam/mul_50 (16/16 flops)
  training/Adam/mul_20 (16/16 flops)
  training/Adam/Square_9 (16/16 flops)
  training/Adam/mul_17 (16/16 flops)
  training/Adam/add_28 (16/16 flops)
  training/Adam/mul_19 (16/16 flops)
  training/Adam/add_12 (16/16 flops)
  training/Adam/truediv_10 (16/16 flops)
  training/Adam/truediv_4 (16/16 flops)
  training/Adam/mul_18 (16/16 flops)
  training/Adam/sub_31 (16/16 flops)
  training/Adam/sub_13 (16/16 flops)
  loss/lambda_1_loss/mul_7 (10/10 flops)
  training/Adam/clip_by_value (1/2 flops)
    training/Adam/clip_by_value/Minimum (1/1 flops)
  training/Adam/sub_60 (1/1 flops)
  training/Adam/sub_56 (1/1 flops)
  training/Adam/sub_33 (1/1 flops)
  training/Adam/sub_57 (1/1 flops)
  training/Adam/sub_62 (1/1 flops)
  training/Adam/sub_6 (1/1 flops)
  training/Adam/sub_59 (1/1 flops)
  training/Adam/sub_45 (1/1 flops)
  training/Adam/sub_146 (1/1 flops)
  training/Adam/sub_35 (1/1 flops)
  training/Adam/sub_36 (1/1 flops)
  training/Adam/sub_38 (1/1 flops)
  training/Adam/sub_39 (1/1 flops)
  training/Adam/sub_41 (1/1 flops)
  training/Adam/sub_42 (1/1 flops)
  training/Adam/sub_44 (1/1 flops)
  training/Adam/sub_54 (1/1 flops)
  training/Adam/gradients/AddN_3 (1/1 flops)
  training/Adam/sub_47 (1/1 flops)
  training/Adam/sub_48 (1/1 flops)
  training/Adam/sub_5 (1/1 flops)
  training/Adam/sub_50 (1/1 flops)
  training/Adam/sub_51 (1/1 flops)
  training/Adam/gradients/AddN_2 (1/1 flops)
  training/Adam/sub_53 (1/1 flops)
  loss/lambda_1_loss/SparseSoftmaxCrossEntropyWithLogits/add (1/1 flops)
  training/Adam/sub_92 (1/1 flops)
  training/Adam/sub_93 (1/1 flops)
  training/Adam/sub_95 (1/1 flops)
  training/Adam/sub_96 (1/1 flops)
  training/Adam/sub_98 (1/1 flops)
  training/Adam/sub_99 (1/1 flops)
  training/Adam/truediv (1/1 flops)
  training/Adam/gradients/AddN_1 (1/1 flops)
  training/Adam/gradients/AddN (1/1 flops)
  loss/lambda_1_loss/SparseSoftmaxCrossEntropyWithLogits/sub (1/1 flops)
  training/Adam/sub_90 (1/1 flops)
  training/Adam/mul (1/1 flops)
  loss/lambda_1_loss/NotEqual (1/1 flops)
  loss/lambda_1_loss/Mean_2 (1/1 flops)
  loss/lambda_1_loss/Mean_1 (1/1 flops)
  loss/lambda_1_loss/Mean (1/1 flops)
  loss/lambda_1_loss/Less_3 (1/1 flops)
  loss/lambda_1_loss/Less_2 (1/1 flops)
  loss/lambda_1_loss/AssignAdd_1 (1/1 flops)
  loss/lambda_1_loss/AssignAdd (1/1 flops)
  training/Adam/sub_78 (1/1 flops)
  training/Adam/add (1/1 flops)
  training/Adam/sub_65 (1/1 flops)
  training/Adam/sub_66 (1/1 flops)
  training/Adam/sub_68 (1/1 flops)
  training/Adam/sub_69 (1/1 flops)
  training/Adam/sub_71 (1/1 flops)
  training/Adam/sub_72 (1/1 flops)
  training/Adam/sub_74 (1/1 flops)
  training/Adam/sub_75 (1/1 flops)
  training/Adam/sub_77 (1/1 flops)
  training/Adam/sub_63 (1/1 flops)
  training/Adam/sub_8 (1/1 flops)
  training/Adam/sub_80 (1/1 flops)
  training/Adam/sub_81 (1/1 flops)
  training/Adam/sub_83 (1/1 flops)
  training/Adam/sub_84 (1/1 flops)
  training/Adam/sub_86 (1/1 flops)
  training/Adam/sub_87 (1/1 flops)
  training/Adam/sub_89 (1/1 flops)
  training/Adam/sub_9 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_5 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/RealDiv_1 (1/1 flops)
  training/Adam/AssignAdd (1/1 flops)
  training/Adam/Pow (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/RealDiv (1/1 flops)
  loss/lambda_1_loss/div_12 (1/1 flops)
  loss/lambda_1_loss/div_11 (1/1 flops)
  loss/lambda_1_loss/div_10 (1/1 flops)
  training/Adam/Pow_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/mul (1/1 flops)
  loss/lambda_1_loss/cond_1/add_6 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/RealDiv_1 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_4 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_3 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_2 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_1 (1/1 flops)
  loss/lambda_1_loss/cond_1/add (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/RealDiv_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/RealDiv_2 (1/1 flops)
  training/Adam/sub (1/1 flops)
  training/Adam/sub_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/RealDiv_1 (1/1 flops)
  loss/lambda_1_loss/add_9 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_2_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/RealDiv_1 (1/1 flops)
  loss/lambda_1_loss/mul_19 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_2_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/mul_grad/Mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/mul (1/1 flops)
  training/Adam/gradients/loss/mul_grad/Mul_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/RealDiv_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/Neg (1/1 flops)
  training/Adam/sub_101 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/RealDiv_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/mul (1/1 flops)
  loss/lambda_1_loss/div_9 (1/1 flops)
  loss/lambda_1_loss/truediv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/RealDiv_2 (1/1 flops)
  loss/mul (1/1 flops)
  loss/lambda_1_loss/div_8 (1/1 flops)
  loss/lambda_1_loss/div_7 (1/1 flops)
  loss/lambda_1_loss/div_6 (1/1 flops)
  loss/lambda_1_loss/div_5 (1/1 flops)
  loss/lambda_1_loss/div_4 (1/1 flops)
  loss/lambda_1_loss/add_11 (1/1 flops)
  training/Adam/sub_138 (1/1 flops)
  training/Adam/sub_14 (1/1 flops)
  training/Adam/sub_140 (1/1 flops)
  training/Adam/sub_141 (1/1 flops)
  loss/lambda_1_loss/add_13 (1/1 flops)
  training/Adam/sub_143 (1/1 flops)
  training/Adam/sub_144 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_19_grad/mul (1/1 flops)
  training/Adam/sub_147 (1/1 flops)
  loss/lambda_1_loss/add_12 (1/1 flops)
  training/Adam/sub_149 (1/1 flops)
  training/Adam/sub_15 (1/1 flops)
  training/Adam/sub_150 (1/1 flops)
  training/Adam/sub_152 (1/1 flops)
  training/Adam/sub_153 (1/1 flops)
  training/Adam/sub_137 (1/1 flops)
  training/Adam/sub_155 (1/1 flops)
  training/Adam/sub_156 (1/1 flops)
  training/Adam/sub_17 (1/1 flops)
  training/Adam/sub_18 (1/1 flops)
  training/Adam/sub_2 (1/1 flops)
  training/Adam/sub_20 (1/1 flops)
  training/Adam/sub_21 (1/1 flops)
  loss/lambda_1_loss/add_10 (1/1 flops)
  training/Adam/sub_23 (1/1 flops)
  training/Adam/sub_24 (1/1 flops)
  training/Adam/sub_26 (1/1 flops)
  training/Adam/sub_27 (1/1 flops)
  training/Adam/sub_29 (1/1 flops)
  training/Adam/sub_3 (1/1 flops)
  training/Adam/sub_30 (1/1 flops)
  training/Adam/sub_119 (1/1 flops)
  training/Adam/sub_102 (1/1 flops)
  training/Adam/sub_104 (1/1 flops)
  training/Adam/sub_105 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/RealDiv (1/1 flops)
  training/Adam/sub_107 (1/1 flops)
  training/Adam/sub_108 (1/1 flops)
  training/Adam/sub_11 (1/1 flops)
  training/Adam/sub_110 (1/1 flops)
  training/Adam/sub_111 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/Neg (1/1 flops)
  training/Adam/sub_113 (1/1 flops)
  training/Adam/sub_114 (1/1 flops)
  training/Adam/sub_116 (1/1 flops)
  training/Adam/sub_117 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/Mean_grad/truediv (1/1 flops)
  training/Adam/sub_32 (1/1 flops)
  training/Adam/sub_12 (1/1 flops)
  training/Adam/sub_120 (1/1 flops)
  training/Adam/sub_122 (1/1 flops)
  training/Adam/sub_123 (1/1 flops)
  training/Adam/sub_125 (1/1 flops)
  training/Adam/sub_126 (1/1 flops)
  training/Adam/sub_128 (1/1 flops)
  training/Adam/sub_129 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/Mean_2_grad/truediv (1/1 flops)
  training/Adam/sub_131 (1/1 flops)
  training/Adam/sub_132 (1/1 flops)
  training/Adam/sub_134 (1/1 flops)
  training/Adam/sub_135 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/Mean_2_grad/Maximum (1/1 flops)

======================End of Report==========================
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              0
-min_occurrence             0
-step                       -1
-order_by                   name
-account_type_regexes       _trainable_variables
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     params
-output                     stdout:

==================Model Analysis Report======================
node name | # parameters
_TFProfRoot (--/2.21m params)
  Adam (--/5 params)
    Adam/beta_1 (1, 1/1 params)
    Adam/beta_2 (1, 1/1 params)
    Adam/decay (1, 1/1 params)
    Adam/iterations (1, 1/1 params)
    Adam/lr (1, 1/1 params)
  DetectionLayer (--/15.39k params)
    DetectionLayer/bias (30, 30/30 params)
    DetectionLayer/kernel (1x1x512x30, 15.36k/15.36k params)
  conv1 (--/1.79k params)
    conv1/bias (64, 64/64 params)
    conv1/kernel (3x3x3x64, 1.73k/1.73k params)
  fire2 (--/11.41k params)
    fire2/expand1x1 (--/1.09k params)
      fire2/expand1x1/bias (64, 64/64 params)
      fire2/expand1x1/kernel (1x1x16x64, 1.02k/1.02k params)
    fire2/expand3x3 (--/9.28k params)
      fire2/expand3x3/bias (64, 64/64 params)
      fire2/expand3x3/kernel (3x3x16x64, 9.22k/9.22k params)
    fire2/squeeze1x1 (--/1.04k params)
      fire2/squeeze1x1/bias (16, 16/16 params)
      fire2/squeeze1x1/kernel (1x1x64x16, 1.02k/1.02k params)
  fire3 (--/12.43k params)
    fire3/expand1x1 (--/1.09k params)
      fire3/expand1x1/bias (64, 64/64 params)
      fire3/expand1x1/kernel (1x1x16x64, 1.02k/1.02k params)
    fire3/expand3x3 (--/9.28k params)
      fire3/expand3x3/bias (64, 64/64 params)
      fire3/expand3x3/kernel (3x3x16x64, 9.22k/9.22k params)
    fire3/squeeze1x1 (--/2.06k params)
      fire3/squeeze1x1/bias (16, 16/16 params)
      fire3/squeeze1x1/kernel (1x1x128x16, 2.05k/2.05k params)
  fire4 (--/45.34k params)
    fire4/expand1x1 (--/4.22k params)
      fire4/expand1x1/bias (128, 128/128 params)
      fire4/expand1x1/kernel (1x1x32x128, 4.10k/4.10k params)
    fire4/expand3x3 (--/36.99k params)
      fire4/expand3x3/bias (128, 128/128 params)
      fire4/expand3x3/kernel (3x3x32x128, 36.86k/36.86k params)
    fire4/squeeze1x1 (--/4.13k params)
      fire4/squeeze1x1/bias (32, 32/32 params)
      fire4/squeeze1x1/kernel (1x1x128x32, 4.10k/4.10k params)
  fire5 (--/49.44k params)
    fire5/expand1x1 (--/4.22k params)
      fire5/expand1x1/bias (128, 128/128 params)
      fire5/expand1x1/kernel (1x1x32x128, 4.10k/4.10k params)
    fire5/expand3x3 (--/36.99k params)
      fire5/expand3x3/bias (128, 128/128 params)
      fire5/expand3x3/kernel (3x3x32x128, 36.86k/36.86k params)
    fire5/squeeze1x1 (--/8.22k params)
      fire5/squeeze1x1/bias (32, 32/32 params)
      fire5/squeeze1x1/kernel (1x1x256x32, 8.19k/8.19k params)
  fire6 (--/104.88k params)
    fire6/expand1x1 (--/9.41k params)
      fire6/expand1x1/bias (192, 192/192 params)
      fire6/expand1x1/kernel (1x1x48x192, 9.22k/9.22k params)
    fire6/expand3x3 (--/83.14k params)
      fire6/expand3x3/bias (192, 192/192 params)
      fire6/expand3x3/kernel (3x3x48x192, 82.94k/82.94k params)
    fire6/squeeze1x1 (--/12.34k params)
      fire6/squeeze1x1/bias (48, 48/48 params)
      fire6/squeeze1x1/kernel (1x1x256x48, 12.29k/12.29k params)
  fire7 (--/111.02k params)
    fire7/expand1x1 (--/9.41k params)
      fire7/expand1x1/bias (192, 192/192 params)
      fire7/expand1x1/kernel (1x1x48x192, 9.22k/9.22k params)
    fire7/expand3x3 (--/83.14k params)
      fire7/expand3x3/bias (192, 192/192 params)
      fire7/expand3x3/kernel (3x3x48x192, 82.94k/82.94k params)
    fire7/squeeze1x1 (--/18.48k params)
      fire7/squeeze1x1/bias (48, 48/48 params)
      fire7/squeeze1x1/kernel (1x1x384x48, 18.43k/18.43k params)
  fire8 (--/188.99k params)
    fire8/expand1x1 (--/16.64k params)
      fire8/expand1x1/bias (256, 256/256 params)
      fire8/expand1x1/kernel (1x1x64x256, 16.38k/16.38k params)
    fire8/expand3x3 (--/147.71k params)
      fire8/expand3x3/bias (256, 256/256 params)
      fire8/expand3x3/kernel (3x3x64x256, 147.46k/147.46k params)
    fire8/squeeze1x1 (--/24.64k params)
      fire8/squeeze1x1/bias (64, 64/64 params)
      fire8/squeeze1x1/kernel (1x1x384x64, 24.58k/24.58k params)
  fire9 (--/197.18k params)
    fire9/expand1x1 (--/16.64k params)
      fire9/expand1x1/bias (256, 256/256 params)
      fire9/expand1x1/kernel (1x1x64x256, 16.38k/16.38k params)
    fire9/expand3x3 (--/147.71k params)
      fire9/expand3x3/bias (256, 256/256 params)
      fire9/expand3x3/kernel (3x3x64x256, 147.46k/147.46k params)
    fire9/squeeze1x1 (--/32.83k params)
      fire9/squeeze1x1/bias (64, 64/64 params)
      fire9/squeeze1x1/kernel (1x1x512x64, 32.77k/32.77k params)
  loss (--/2 params)
    loss/lambda_1_loss (--/2 params)
      loss/lambda_1_loss/Variable (1, 1/1 params)
      loss/lambda_1_loss/Variable_1 (1, 1/1 params)
  training (--/1.48m params)
    training/Adam (--/1.48m params)
      training/Adam/Variable (3x3x3x64, 1.73k/1.73k params)
      training/Adam/Variable_1 (64, 64/64 params)
      training/Adam/Variable_10 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_100 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_101 (256, 256/256 params)
      training/Adam/Variable_102 (1x1x512x30, 15.36k/15.36k params)
      training/Adam/Variable_103 (30, 30/30 params)
      training/Adam/Variable_104 (1, 1/1 params)
      training/Adam/Variable_105 (1, 1/1 params)
      training/Adam/Variable_106 (1, 1/1 params)
      training/Adam/Variable_107 (1, 1/1 params)
      training/Adam/Variable_108 (1, 1/1 params)
      training/Adam/Variable_109 (1, 1/1 params)
      training/Adam/Variable_11 (64, 64/64 params)
      training/Adam/Variable_110 (1, 1/1 params)
      training/Adam/Variable_111 (1, 1/1 params)
      training/Adam/Variable_112 (1, 1/1 params)
      training/Adam/Variable_113 (1, 1/1 params)
      training/Adam/Variable_114 (1, 1/1 params)
      training/Adam/Variable_115 (1, 1/1 params)
      training/Adam/Variable_116 (1, 1/1 params)
      training/Adam/Variable_117 (1, 1/1 params)
      training/Adam/Variable_118 (1, 1/1 params)
      training/Adam/Variable_119 (1, 1/1 params)
      training/Adam/Variable_12 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_120 (1, 1/1 params)
      training/Adam/Variable_121 (1, 1/1 params)
      training/Adam/Variable_122 (1, 1/1 params)
      training/Adam/Variable_123 (1, 1/1 params)
      training/Adam/Variable_124 (1, 1/1 params)
      training/Adam/Variable_125 (1, 1/1 params)
      training/Adam/Variable_126 (1, 1/1 params)
      training/Adam/Variable_127 (1, 1/1 params)
      training/Adam/Variable_128 (1, 1/1 params)
      training/Adam/Variable_129 (1, 1/1 params)
      training/Adam/Variable_13 (64, 64/64 params)
      training/Adam/Variable_130 (1, 1/1 params)
      training/Adam/Variable_131 (1, 1/1 params)
      training/Adam/Variable_132 (1, 1/1 params)
      training/Adam/Variable_133 (1, 1/1 params)
      training/Adam/Variable_134 (1, 1/1 params)
      training/Adam/Variable_135 (1, 1/1 params)
      training/Adam/Variable_136 (1, 1/1 params)
      training/Adam/Variable_137 (1, 1/1 params)
      training/Adam/Variable_138 (1, 1/1 params)
      training/Adam/Variable_139 (1, 1/1 params)
      training/Adam/Variable_14 (1x1x128x32, 4.10k/4.10k params)
      training/Adam/Variable_140 (1, 1/1 params)
      training/Adam/Variable_141 (1, 1/1 params)
      training/Adam/Variable_142 (1, 1/1 params)
      training/Adam/Variable_143 (1, 1/1 params)
      training/Adam/Variable_144 (1, 1/1 params)
      training/Adam/Variable_145 (1, 1/1 params)
      training/Adam/Variable_146 (1, 1/1 params)
      training/Adam/Variable_147 (1, 1/1 params)
      training/Adam/Variable_148 (1, 1/1 params)
      training/Adam/Variable_149 (1, 1/1 params)
      training/Adam/Variable_15 (32, 32/32 params)
      training/Adam/Variable_150 (1, 1/1 params)
      training/Adam/Variable_151 (1, 1/1 params)
      training/Adam/Variable_152 (1, 1/1 params)
      training/Adam/Variable_153 (1, 1/1 params)
      training/Adam/Variable_154 (1, 1/1 params)
      training/Adam/Variable_155 (1, 1/1 params)
      training/Adam/Variable_16 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_17 (128, 128/128 params)
      training/Adam/Variable_18 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_19 (128, 128/128 params)
      training/Adam/Variable_2 (1x1x64x16, 1.02k/1.02k params)
      training/Adam/Variable_20 (1x1x256x32, 8.19k/8.19k params)
      training/Adam/Variable_21 (32, 32/32 params)
      training/Adam/Variable_22 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_23 (128, 128/128 params)
      training/Adam/Variable_24 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_25 (128, 128/128 params)
      training/Adam/Variable_26 (1x1x256x48, 12.29k/12.29k params)
      training/Adam/Variable_27 (48, 48/48 params)
      training/Adam/Variable_28 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_29 (192, 192/192 params)
      training/Adam/Variable_3 (16, 16/16 params)
      training/Adam/Variable_30 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_31 (192, 192/192 params)
      training/Adam/Variable_32 (1x1x384x48, 18.43k/18.43k params)
      training/Adam/Variable_33 (48, 48/48 params)
      training/Adam/Variable_34 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_35 (192, 192/192 params)
      training/Adam/Variable_36 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_37 (192, 192/192 params)
      training/Adam/Variable_38 (1x1x384x64, 24.58k/24.58k params)
      training/Adam/Variable_39 (64, 64/64 params)
      training/Adam/Variable_4 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_40 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_41 (256, 256/256 params)
      training/Adam/Variable_42 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_43 (256, 256/256 params)
      training/Adam/Variable_44 (1x1x512x64, 32.77k/32.77k params)
      training/Adam/Variable_45 (64, 64/64 params)
      training/Adam/Variable_46 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_47 (256, 256/256 params)
      training/Adam/Variable_48 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_49 (256, 256/256 params)
      training/Adam/Variable_5 (64, 64/64 params)
      training/Adam/Variable_50 (1x1x512x30, 15.36k/15.36k params)
      training/Adam/Variable_51 (30, 30/30 params)
      training/Adam/Variable_52 (3x3x3x64, 1.73k/1.73k params)
      training/Adam/Variable_53 (64, 64/64 params)
      training/Adam/Variable_54 (1x1x64x16, 1.02k/1.02k params)
      training/Adam/Variable_55 (16, 16/16 params)
      training/Adam/Variable_56 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_57 (64, 64/64 params)
      training/Adam/Variable_58 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_59 (64, 64/64 params)
      training/Adam/Variable_6 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_60 (1x1x128x16, 2.05k/2.05k params)
      training/Adam/Variable_61 (16, 16/16 params)
      training/Adam/Variable_62 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_63 (64, 64/64 params)
      training/Adam/Variable_64 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_65 (64, 64/64 params)
      training/Adam/Variable_66 (1x1x128x32, 4.10k/4.10k params)
      training/Adam/Variable_67 (32, 32/32 params)
      training/Adam/Variable_68 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_69 (128, 128/128 params)
      training/Adam/Variable_7 (64, 64/64 params)
      training/Adam/Variable_70 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_71 (128, 128/128 params)
      training/Adam/Variable_72 (1x1x256x32, 8.19k/8.19k params)
      training/Adam/Variable_73 (32, 32/32 params)
      training/Adam/Variable_74 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_75 (128, 128/128 params)
      training/Adam/Variable_76 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_77 (128, 128/128 params)
      training/Adam/Variable_78 (1x1x256x48, 12.29k/12.29k params)
      training/Adam/Variable_79 (48, 48/48 params)
      training/Adam/Variable_8 (1x1x128x16, 2.05k/2.05k params)
      training/Adam/Variable_80 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_81 (192, 192/192 params)
      training/Adam/Variable_82 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_83 (192, 192/192 params)
      training/Adam/Variable_84 (1x1x384x48, 18.43k/18.43k params)
      training/Adam/Variable_85 (48, 48/48 params)
      training/Adam/Variable_86 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_87 (192, 192/192 params)
      training/Adam/Variable_88 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_89 (192, 192/192 params)
      training/Adam/Variable_9 (16, 16/16 params)
      training/Adam/Variable_90 (1x1x384x64, 24.58k/24.58k params)
      training/Adam/Variable_91 (64, 64/64 params)
      training/Adam/Variable_92 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_93 (256, 256/256 params)
      training/Adam/Variable_94 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_95 (256, 256/256 params)
      training/Adam/Variable_96 (1x1x512x64, 32.77k/32.77k params)
      training/Adam/Variable_97 (64, 64/64 params)
      training/Adam/Variable_98 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_99 (256, 256/256 params)

======================End of Report==========================
1,486,190,643 --- 2,213,717
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================
node name | # float_ops
_TFProfRoot (--/1.49b flops)
  model_1/fire2/expand3x3/convolution (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire3/expand3x3/convolution_grad/Conv2DBackpropInput (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire3/expand3x3/convolution_grad/Conv2DBackpropFilter (55.76m/55.76m flops)
  model_1/fire3/expand3x3/convolution (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire2/expand3x3/convolution_grad/Conv2DBackpropFilter (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire2/expand3x3/convolution_grad/Conv2DBackpropInput (55.76m/55.76m flops)
  training/Adam/gradients/model_1/fire4/expand3x3/convolution_grad/Conv2DBackpropFilter (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire4/expand3x3/convolution_grad/Conv2DBackpropInput (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire5/expand3x3/convolution_grad/Conv2DBackpropFilter (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire5/expand3x3/convolution_grad/Conv2DBackpropInput (53.75m/53.75m flops)
  model_1/fire4/expand3x3/convolution (53.75m/53.75m flops)
  model_1/fire5/expand3x3/convolution (53.75m/53.75m flops)
  training/Adam/gradients/model_1/fire8/expand3x3/convolution_grad/Conv2DBackpropFilter (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire8/expand3x3/convolution_grad/Conv2DBackpropInput (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire9/expand3x3/convolution_grad/Conv2DBackpropFilter (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire9/expand3x3/convolution_grad/Conv2DBackpropInput (49.84m/49.84m flops)
  model_1/fire8/expand3x3/convolution (49.84m/49.84m flops)
  model_1/fire9/expand3x3/convolution (49.84m/49.84m flops)
  training/Adam/gradients/model_1/fire7/expand3x3/convolution_grad/Conv2DBackpropInput (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire7/expand3x3/convolution_grad/Conv2DBackpropFilter (28.04m/28.04m flops)
  model_1/fire6/expand3x3/convolution (28.04m/28.04m flops)
  model_1/fire7/expand3x3/convolution (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire6/expand3x3/convolution_grad/Conv2DBackpropInput (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire6/expand3x3/convolution_grad/Conv2DBackpropFilter (28.04m/28.04m flops)
  training/Adam/gradients/model_1/fire3/squeeze1x1/convolution_grad/Conv2DBackpropInput (12.39m/12.39m flops)
  training/Adam/gradients/model_1/fire3/squeeze1x1/convolution_grad/Conv2DBackpropFilter (12.39m/12.39m flops)
  model_1/fire3/squeeze1x1/convolution (12.39m/12.39m flops)
  model_1/fire5/squeeze1x1/convolution (11.94m/11.94m flops)
  training/Adam/gradients/model_1/fire5/squeeze1x1/convolution_grad/Conv2DBackpropFilter (11.94m/11.94m flops)
  training/Adam/gradients/model_1/fire5/squeeze1x1/convolution_grad/Conv2DBackpropInput (11.94m/11.94m flops)
  model_1/fire9/squeeze1x1/convolution (11.08m/11.08m flops)
  training/Adam/gradients/model_1/fire9/squeeze1x1/convolution_grad/Conv2DBackpropFilter (11.08m/11.08m flops)
  training/Adam/gradients/model_1/fire9/squeeze1x1/convolution_grad/Conv2DBackpropInput (11.08m/11.08m flops)
  model_1/fire8/squeeze1x1/convolution (8.31m/8.31m flops)
  training/Adam/gradients/model_1/fire8/squeeze1x1/convolution_grad/Conv2DBackpropFilter (8.31m/8.31m flops)
  training/Adam/gradients/model_1/fire8/squeeze1x1/convolution_grad/Conv2DBackpropInput (8.31m/8.31m flops)
  model_1/fire7/squeeze1x1/convolution (6.23m/6.23m flops)
  training/Adam/gradients/model_1/fire7/squeeze1x1/convolution_grad/Conv2DBackpropFilter (6.23m/6.23m flops)
  training/Adam/gradients/model_1/fire7/squeeze1x1/convolution_grad/Conv2DBackpropInput (6.23m/6.23m flops)
  model_1/fire2/squeeze1x1/convolution (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/squeeze1x1/convolution_grad/Conv2DBackpropFilter (6.20m/6.20m flops)
  model_1/fire2/expand1x1/convolution (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/squeeze1x1/convolution_grad/Conv2DBackpropInput (6.20m/6.20m flops)
  model_1/fire3/expand1x1/convolution (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire3/expand1x1/convolution_grad/Conv2DBackpropInput (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/expand1x1/convolution_grad/Conv2DBackpropInput (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire2/expand1x1/convolution_grad/Conv2DBackpropFilter (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire3/expand1x1/convolution_grad/Conv2DBackpropFilter (6.20m/6.20m flops)
  training/Adam/gradients/model_1/fire4/expand1x1/convolution_grad/Conv2DBackpropInput (5.97m/5.97m flops)
  model_1/fire5/expand1x1/convolution (5.97m/5.97m flops)
  model_1/fire4/squeeze1x1/convolution (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire5/expand1x1/convolution_grad/Conv2DBackpropInput (5.97m/5.97m flops)
  model_1/fire4/expand1x1/convolution (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire5/expand1x1/convolution_grad/Conv2DBackpropFilter (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire4/squeeze1x1/convolution_grad/Conv2DBackpropInput (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire4/squeeze1x1/convolution_grad/Conv2DBackpropFilter (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire4/expand1x1/convolution_grad/Conv2DBackpropFilter (5.97m/5.97m flops)
  training/Adam/gradients/model_1/fire8/expand1x1/convolution_grad/Conv2DBackpropInput (5.54m/5.54m flops)
  training/Adam/gradients/model_1/fire9/expand1x1/convolution_grad/Conv2DBackpropFilter (5.54m/5.54m flops)
  training/Adam/gradients/model_1/fire9/expand1x1/convolution_grad/Conv2DBackpropInput (5.54m/5.54m flops)
  training/Adam/gradients/model_1/fire8/expand1x1/convolution_grad/Conv2DBackpropFilter (5.54m/5.54m flops)
  model_1/fire8/expand1x1/convolution (5.54m/5.54m flops)
  model_1/fire9/expand1x1/convolution (5.54m/5.54m flops)
  DetectionLayer/convolution (5.19m/5.19m flops)
  training/Adam/gradients/DetectionLayer/convolution_grad/Conv2DBackpropFilter (5.19m/5.19m flops)
  training/Adam/gradients/DetectionLayer/convolution_grad/Conv2DBackpropInput (5.19m/5.19m flops)
  model_1/fire6/squeeze1x1/convolution (4.15m/4.15m flops)
  training/Adam/gradients/model_1/fire6/squeeze1x1/convolution_grad/Conv2DBackpropInput (4.15m/4.15m flops)
  training/Adam/gradients/model_1/fire6/squeeze1x1/convolution_grad/Conv2DBackpropFilter (4.15m/4.15m flops)
  model_1/fire7/expand1x1/convolution (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire7/expand1x1/convolution_grad/Conv2DBackpropInput (3.12m/3.12m flops)
  model_1/fire6/expand1x1/convolution (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire7/expand1x1/convolution_grad/Conv2DBackpropFilter (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire6/expand1x1/convolution_grad/Conv2DBackpropInput (3.12m/3.12m flops)
  training/Adam/gradients/model_1/fire6/expand1x1/convolution_grad/Conv2DBackpropFilter (3.12m/3.12m flops)
  training/Adam/gradients/model_1/pool1/MaxPool_grad/MaxPoolGrad (1.94m/1.94m flops)
  model_1/pool1/MaxPool (1.74m/1.74m flops)
  training/Adam/gradients/model_1/pool3/MaxPool_grad/MaxPoolGrad (933.12k/933.12k flops)
  model_1/pool3/MaxPool (839.81k/839.81k flops)
  model_1/conv1/BiasAdd (788.54k/788.54k flops)
  training/Adam/gradients/model_1/conv1/BiasAdd_grad/BiasAddGrad (788.48k/788.48k flops)
  training/Adam/gradients/model_1/pool5/MaxPool_grad/MaxPoolGrad (432.64k/432.64k flops)
  model_1/pool5/MaxPool (389.38k/389.38k flops)
  fire9/expand3x3/random_uniform (147.46k/294.91k flops)
    fire9/expand3x3/random_uniform/mul (147.46k/147.46k flops)
    fire9/expand3x3/random_uniform/sub (1/1 flops)
  fire8/expand3x3/random_uniform (147.46k/294.91k flops)
    fire8/expand3x3/random_uniform/mul (147.46k/147.46k flops)
    fire8/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_49 (147.46k/294.91k flops)
    training/Adam/clip_by_value_49/Minimum (147.46k/147.46k flops)
  training/Adam/clip_by_value_43 (147.46k/294.91k flops)
    training/Adam/clip_by_value_43/Minimum (147.46k/147.46k flops)
  model_1/fire3/expand3x3/BiasAdd (193.60k/193.60k flops)
  model_1/fire2/expand1x1/BiasAdd (193.60k/193.60k flops)
  model_1/fire2/expand3x3/BiasAdd (193.60k/193.60k flops)
  model_1/fire3/expand1x1/BiasAdd (193.60k/193.60k flops)
  training/Adam/gradients/model_1/fire2/expand3x3/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  training/Adam/gradients/model_1/fire3/expand1x1/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  training/Adam/gradients/model_1/fire3/expand3x3/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  training/Adam/gradients/model_1/fire2/expand1x1/BiasAdd_grad/BiasAddGrad (193.54k/193.54k flops)
  fire7/expand3x3/random_uniform (82.94k/165.89k flops)
    fire7/expand3x3/random_uniform/mul (82.94k/82.94k flops)
    fire7/expand3x3/random_uniform/sub (1/1 flops)
  fire6/expand3x3/random_uniform (82.94k/165.89k flops)
    fire6/expand3x3/random_uniform/mul (82.94k/82.94k flops)
    fire6/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_31 (82.94k/165.89k flops)
    training/Adam/clip_by_value_31/Minimum (82.94k/82.94k flops)
  training/Adam/clip_by_value_37 (82.94k/165.89k flops)
    training/Adam/clip_by_value_37/Minimum (82.94k/82.94k flops)
  training/Adam/add_129 (147.46k/147.46k flops)
  training/Adam/mul_241 (147.46k/147.46k flops)
  training/Adam/sub_148 (147.46k/147.46k flops)
  training/Adam/mul_242 (147.46k/147.46k flops)
  training/Adam/mul_211 (147.46k/147.46k flops)
  training/Adam/mul_212 (147.46k/147.46k flops)
  training/Adam/sub_130 (147.46k/147.46k flops)
  training/Adam/add_127 (147.46k/147.46k flops)
  training/Adam/truediv_49 (147.46k/147.46k flops)
  training/Adam/add_128 (147.46k/147.46k flops)
  training/Adam/truediv_43 (147.46k/147.46k flops)
  training/Adam/mul_215 (147.46k/147.46k flops)
  training/Adam/mul_214 (147.46k/147.46k flops)
  training/Adam/mul_213 (147.46k/147.46k flops)
  training/Adam/mul_244 (147.46k/147.46k flops)
  training/Adam/mul_245 (147.46k/147.46k flops)
  training/Adam/Square_48 (147.46k/147.46k flops)
  training/Adam/add_145 (147.46k/147.46k flops)
  training/Adam/add_146 (147.46k/147.46k flops)
  training/Adam/add_147 (147.46k/147.46k flops)
  training/Adam/mul_243 (147.46k/147.46k flops)
  training/Adam/Square_42 (147.46k/147.46k flops)
  model_1/fire5/expand1x1/BiasAdd (93.31k/93.31k flops)
  model_1/fire4/expand1x1/BiasAdd (93.31k/93.31k flops)
  model_1/fire4/expand3x3/BiasAdd (93.31k/93.31k flops)
  model_1/fire5/expand3x3/BiasAdd (93.31k/93.31k flops)
  training/Adam/gradients/model_1/fire5/expand3x3/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/gradients/model_1/fire4/expand1x1/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/gradients/model_1/fire5/expand1x1/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/gradients/model_1/fire4/expand3x3/BiasAdd_grad/BiasAddGrad (93.18k/93.18k flops)
  training/Adam/sub_94 (82.94k/82.94k flops)
  training/Adam/add_109 (82.94k/82.94k flops)
  training/Adam/sub_112 (82.94k/82.94k flops)
  training/Adam/add_111 (82.94k/82.94k flops)
  training/Adam/add_110 (82.94k/82.94k flops)
  training/Adam/add_91 (82.94k/82.94k flops)
  training/Adam/mul_151 (82.94k/82.94k flops)
  training/Adam/mul_152 (82.94k/82.94k flops)
  training/Adam/mul_153 (82.94k/82.94k flops)
  training/Adam/mul_154 (82.94k/82.94k flops)
  training/Adam/mul_155 (82.94k/82.94k flops)
  training/Adam/Square_36 (82.94k/82.94k flops)
  training/Adam/Square_30 (82.94k/82.94k flops)
  training/Adam/mul_185 (82.94k/82.94k flops)
  training/Adam/mul_184 (82.94k/82.94k flops)
  training/Adam/mul_181 (82.94k/82.94k flops)
  training/Adam/mul_183 (82.94k/82.94k flops)
  training/Adam/mul_182 (82.94k/82.94k flops)
  training/Adam/truediv_37 (82.94k/82.94k flops)
  training/Adam/add_92 (82.94k/82.94k flops)
  training/Adam/truediv_31 (82.94k/82.94k flops)
  training/Adam/add_93 (82.94k/82.94k flops)
  fire5/expand3x3/random_uniform (36.86k/73.73k flops)
    fire5/expand3x3/random_uniform/mul (36.86k/36.86k flops)
    fire5/expand3x3/random_uniform/sub (1/1 flops)
  fire4/expand3x3/random_uniform (36.86k/73.73k flops)
    fire4/expand3x3/random_uniform/mul (36.86k/36.86k flops)
    fire4/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_19 (36.86k/73.73k flops)
    training/Adam/clip_by_value_19/Minimum (36.86k/36.86k flops)
  training/Adam/clip_by_value_25 (36.86k/73.73k flops)
    training/Adam/clip_by_value_25/Minimum (36.86k/36.86k flops)
  fire9/squeeze1x1/random_uniform (32.77k/65.54k flops)
    fire9/squeeze1x1/random_uniform/mul (32.77k/32.77k flops)
    fire9/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_45 (32.77k/65.54k flops)
    training/Adam/clip_by_value_45/Minimum (32.77k/32.77k flops)
  fire8/squeeze1x1/random_uniform (24.58k/49.15k flops)
    fire8/squeeze1x1/random_uniform/mul (24.58k/24.58k flops)
    fire8/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_39 (24.58k/49.15k flops)
    training/Adam/clip_by_value_39/Minimum (24.58k/24.58k flops)
  training/Adam/gradients/AddN_17 (48.40k/48.40k flops)
  training/Adam/gradients/AddN_16 (48.40k/48.40k flops)
  model_1/fire2/squeeze1x1/BiasAdd (48.40k/48.40k flops)
  model_1/fire3/squeeze1x1/BiasAdd (48.40k/48.40k flops)
  training/Adam/gradients/model_1/fire3/squeeze1x1/BiasAdd_grad/BiasAddGrad (48.38k/48.38k flops)
  training/Adam/gradients/model_1/fire2/squeeze1x1/BiasAdd_grad/BiasAddGrad (48.38k/48.38k flops)
  model_1/fire8/expand1x1/BiasAdd (43.26k/43.26k flops)
  model_1/fire8/expand3x3/BiasAdd (43.26k/43.26k flops)
  model_1/fire9/expand1x1/BiasAdd (43.26k/43.26k flops)
  model_1/fire9/expand3x3/BiasAdd (43.26k/43.26k flops)
  training/Adam/gradients/model_1/fire9/expand1x1/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  training/Adam/gradients/model_1/fire8/expand1x1/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  training/Adam/gradients/model_1/fire8/expand3x3/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  training/Adam/gradients/model_1/fire9/expand3x3/BiasAdd_grad/BiasAddGrad (43.01k/43.01k flops)
  fire7/squeeze1x1/random_uniform (18.43k/36.87k flops)
    fire7/squeeze1x1/random_uniform/mul (18.43k/18.43k flops)
    fire7/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/add_73 (36.86k/36.86k flops)
  training/Adam/add_74 (36.86k/36.86k flops)
  training/Adam/add_75 (36.86k/36.86k flops)
  training/Adam/Square_24 (36.86k/36.86k flops)
  training/Adam/sub_58 (36.86k/36.86k flops)
  training/Adam/add_57 (36.86k/36.86k flops)
  training/Adam/mul_125 (36.86k/36.86k flops)
  training/Adam/Square_18 (36.86k/36.86k flops)
  training/Adam/mul_124 (36.86k/36.86k flops)
  training/Adam/add_55 (36.86k/36.86k flops)
  training/Adam/mul_122 (36.86k/36.86k flops)
  training/Adam/mul_121 (36.86k/36.86k flops)
  training/Adam/add_56 (36.86k/36.86k flops)
  training/Adam/mul_123 (36.86k/36.86k flops)
  training/Adam/truediv_19 (36.86k/36.86k flops)
  training/Adam/mul_91 (36.86k/36.86k flops)
  training/Adam/sub_76 (36.86k/36.86k flops)
  training/Adam/mul_92 (36.86k/36.86k flops)
  training/Adam/clip_by_value_33 (18.43k/36.86k flops)
    training/Adam/clip_by_value_33/Minimum (18.43k/18.43k flops)
  training/Adam/mul_93 (36.86k/36.86k flops)
  training/Adam/truediv_25 (36.86k/36.86k flops)
  training/Adam/mul_95 (36.86k/36.86k flops)
  training/Adam/mul_94 (36.86k/36.86k flops)
  fire8/expand1x1/random_uniform (16.38k/32.77k flops)
    fire8/expand1x1/random_uniform/mul (16.38k/16.38k flops)
    fire8/expand1x1/random_uniform/sub (1/1 flops)
  fire9/expand1x1/random_uniform (16.38k/32.77k flops)
    fire9/expand1x1/random_uniform/mul (16.38k/16.38k flops)
    fire9/expand1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_41 (16.38k/32.77k flops)
    training/Adam/clip_by_value_41/Minimum (16.38k/16.38k flops)
  training/Adam/add_135 (32.77k/32.77k flops)
  training/Adam/add_134 (32.77k/32.77k flops)
  training/Adam/add_133 (32.77k/32.77k flops)
  training/Adam/truediv_45 (32.77k/32.77k flops)
  training/Adam/Square_44 (32.77k/32.77k flops)
  training/Adam/clip_by_value_47 (16.38k/32.77k flops)
    training/Adam/clip_by_value_47/Minimum (16.38k/16.38k flops)
  training/Adam/mul_221 (32.77k/32.77k flops)
  training/Adam/mul_222 (32.77k/32.77k flops)
  training/Adam/mul_223 (32.77k/32.77k flops)
  training/Adam/mul_224 (32.77k/32.77k flops)
  training/Adam/mul_225 (32.77k/32.77k flops)
  training/Adam/sub_136 (32.77k/32.77k flops)
  model_1/fire7/expand1x1/BiasAdd (32.45k/32.45k flops)
  model_1/fire7/expand3x3/BiasAdd (32.45k/32.45k flops)
  model_1/fire6/expand3x3/BiasAdd (32.45k/32.45k flops)
  model_1/fire6/expand1x1/BiasAdd (32.45k/32.45k flops)
  training/Adam/gradients/model_1/fire6/expand3x3/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/gradients/model_1/fire6/expand1x1/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/gradients/model_1/fire7/expand3x3/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/gradients/model_1/fire7/expand1x1/BiasAdd_grad/BiasAddGrad (32.26k/32.26k flops)
  training/Adam/clip_by_value_51 (15.36k/30.72k flops)
    training/Adam/clip_by_value_51/Minimum (15.36k/15.36k flops)
  DetectionLayer/truncated_normal (15.36k/30.72k flops)
    DetectionLayer/truncated_normal/mul (15.36k/15.36k flops)
  fire6/squeeze1x1/random_uniform (12.29k/24.58k flops)
    fire6/squeeze1x1/random_uniform/mul (12.29k/12.29k flops)
    fire6/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/mul_195 (24.58k/24.58k flops)
  training/Adam/add_116 (24.58k/24.58k flops)
  training/Adam/clip_by_value_27 (12.29k/24.58k flops)
    training/Adam/clip_by_value_27/Minimum (12.29k/12.29k flops)
  training/Adam/truediv_39 (24.58k/24.58k flops)
  training/Adam/add_115 (24.58k/24.58k flops)
  training/Adam/sub_118 (24.58k/24.58k flops)
  training/Adam/add_117 (24.58k/24.58k flops)
  training/Adam/mul_194 (24.58k/24.58k flops)
  training/Adam/mul_193 (24.58k/24.58k flops)
  training/Adam/Square_38 (24.58k/24.58k flops)
  training/Adam/mul_191 (24.58k/24.58k flops)
  training/Adam/mul_192 (24.58k/24.58k flops)
  model_1/fire5/squeeze1x1/BiasAdd (23.33k/23.33k flops)
  training/Adam/gradients/AddN_14 (23.33k/23.33k flops)
  training/Adam/gradients/AddN_15 (23.33k/23.33k flops)
  model_1/fire4/squeeze1x1/BiasAdd (23.33k/23.33k flops)
  training/Adam/gradients/model_1/fire5/squeeze1x1/BiasAdd_grad/BiasAddGrad (23.30k/23.30k flops)
  training/Adam/gradients/model_1/fire4/squeeze1x1/BiasAdd_grad/BiasAddGrad (23.30k/23.30k flops)
  fire7/expand1x1/random_uniform (9.22k/18.43k flops)
    fire7/expand1x1/random_uniform/mul (9.22k/9.22k flops)
    fire7/expand1x1/random_uniform/sub (1/1 flops)
  fire6/expand1x1/random_uniform (9.22k/18.43k flops)
    fire6/expand1x1/random_uniform/mul (9.22k/9.22k flops)
    fire6/expand1x1/random_uniform/sub (1/1 flops)
  fire3/expand3x3/random_uniform (9.22k/18.43k flops)
    fire3/expand3x3/random_uniform/mul (9.22k/9.22k flops)
    fire3/expand3x3/random_uniform/sub (1/1 flops)
  fire2/expand3x3/random_uniform (9.22k/18.43k flops)
    fire2/expand3x3/random_uniform/mul (9.22k/9.22k flops)
    fire2/expand3x3/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_7 (9.22k/18.43k flops)
    training/Adam/clip_by_value_7/Minimum (9.22k/9.22k flops)
  training/Adam/clip_by_value_29 (9.22k/18.43k flops)
    training/Adam/clip_by_value_29/Minimum (9.22k/9.22k flops)
  training/Adam/sub_100 (18.43k/18.43k flops)
  training/Adam/clip_by_value_13 (9.22k/18.43k flops)
    training/Adam/clip_by_value_13/Minimum (9.22k/9.22k flops)
  training/Adam/truediv_33 (18.43k/18.43k flops)
  training/Adam/add_99 (18.43k/18.43k flops)
  training/Adam/add_98 (18.43k/18.43k flops)
  training/Adam/add_97 (18.43k/18.43k flops)
  training/Adam/clip_by_value_35 (9.22k/18.43k flops)
    training/Adam/clip_by_value_35/Minimum (9.22k/9.22k flops)
  training/Adam/mul_162 (18.43k/18.43k flops)
  training/Adam/mul_165 (18.43k/18.43k flops)
  training/Adam/mul_164 (18.43k/18.43k flops)
  training/Adam/Square_32 (18.43k/18.43k flops)
  training/Adam/mul_163 (18.43k/18.43k flops)
  training/Adam/mul_161 (18.43k/18.43k flops)
  loss/lambda_1_loss/Maximum_3 (16.90k/16.90k flops)
  loss/lambda_1_loss/sub_6 (16.90k/16.90k flops)
  loss/lambda_1_loss/Maximum_2 (16.90k/16.90k flops)
  loss/lambda_1_loss/Minimum_1 (16.90k/16.90k flops)
  fire5/squeeze1x1/random_uniform (8.19k/16.39k flops)
    fire5/squeeze1x1/random_uniform/mul (8.19k/8.19k flops)
    fire5/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/mul_204 (16.38k/16.38k flops)
  training/Adam/mul_231 (16.38k/16.38k flops)
  training/Adam/mul_232 (16.38k/16.38k flops)
  training/Adam/mul_203 (16.38k/16.38k flops)
  training/Adam/mul_205 (16.38k/16.38k flops)
  training/Adam/Square_40 (16.38k/16.38k flops)
  training/Adam/add_141 (16.38k/16.38k flops)
  training/Adam/add_140 (16.38k/16.38k flops)
  training/Adam/mul_233 (16.38k/16.38k flops)
  training/Adam/add_139 (16.38k/16.38k flops)
  training/Adam/sub_142 (16.38k/16.38k flops)
  training/Adam/mul_234 (16.38k/16.38k flops)
  training/Adam/mul_235 (16.38k/16.38k flops)
  training/Adam/clip_by_value_21 (8.19k/16.38k flops)
    training/Adam/clip_by_value_21/Minimum (8.19k/8.19k flops)
  training/Adam/truediv_47 (16.38k/16.38k flops)
  training/Adam/truediv_41 (16.38k/16.38k flops)
  training/Adam/mul_202 (16.38k/16.38k flops)
  training/Adam/sub_124 (16.38k/16.38k flops)
  training/Adam/Square_46 (16.38k/16.38k flops)
  training/Adam/mul_201 (16.38k/16.38k flops)
  training/Adam/add_121 (16.38k/16.38k flops)
  training/Adam/add_123 (16.38k/16.38k flops)
  training/Adam/add_122 (16.38k/16.38k flops)
  training/Adam/truediv_51 (15.36k/15.36k flops)
  training/Adam/Square_50 (15.36k/15.36k flops)
  training/Adam/sub_154 (15.36k/15.36k flops)
  training/Adam/mul_254 (15.36k/15.36k flops)
  training/Adam/add_151 (15.36k/15.36k flops)
  training/Adam/add_152 (15.36k/15.36k flops)
  training/Adam/add_153 (15.36k/15.36k flops)
  training/Adam/mul_251 (15.36k/15.36k flops)
  training/Adam/mul_252 (15.36k/15.36k flops)
  training/Adam/mul_253 (15.36k/15.36k flops)
  training/Adam/mul_255 (15.36k/15.36k flops)
  training/Adam/gradients/AddN_9 (15.21k/15.21k flops)
  training/Adam/Square_26 (12.29k/12.29k flops)
  training/Adam/truediv_27 (12.29k/12.29k flops)
  training/Adam/mul_131 (12.29k/12.29k flops)
  training/Adam/add_79 (12.29k/12.29k flops)
  training/Adam/add_81 (12.29k/12.29k flops)
  training/Adam/mul_132 (12.29k/12.29k flops)
  training/Adam/mul_133 (12.29k/12.29k flops)
  training/Adam/mul_135 (12.29k/12.29k flops)
  training/Adam/add_80 (12.29k/12.29k flops)
  training/Adam/sub_82 (12.29k/12.29k flops)
  training/Adam/mul_134 (12.29k/12.29k flops)
  model_1/fire8/squeeze1x1/BiasAdd (10.82k/10.82k flops)
  training/Adam/gradients/AddN_10 (10.82k/10.82k flops)
  training/Adam/gradients/AddN_11 (10.82k/10.82k flops)
  model_1/fire9/squeeze1x1/BiasAdd (10.82k/10.82k flops)
  training/Adam/gradients/model_1/fire8/squeeze1x1/BiasAdd_grad/BiasAddGrad (10.75k/10.75k flops)
  training/Adam/gradients/model_1/fire9/squeeze1x1/BiasAdd_grad/BiasAddGrad (10.75k/10.75k flops)
  training/Adam/add_39 (9.22k/9.22k flops)
  training/Adam/add_38 (9.22k/9.22k flops)
  training/Adam/mul_33 (9.22k/9.22k flops)
  training/Adam/mul_32 (9.22k/9.22k flops)
  training/Adam/mul_175 (9.22k/9.22k flops)
  training/Adam/mul_31 (9.22k/9.22k flops)
  training/Adam/mul_65 (9.22k/9.22k flops)
  training/Adam/mul_174 (9.22k/9.22k flops)
  training/Adam/mul_34 (9.22k/9.22k flops)
  training/Adam/mul_171 (9.22k/9.22k flops)
  training/Adam/Square_12 (9.22k/9.22k flops)
  training/Adam/truediv_7 (9.22k/9.22k flops)
  training/Adam/mul_173 (9.22k/9.22k flops)
  training/Adam/mul_172 (9.22k/9.22k flops)
  training/Adam/mul_35 (9.22k/9.22k flops)
  training/Adam/Square_28 (9.22k/9.22k flops)
  training/Adam/Square_34 (9.22k/9.22k flops)
  training/Adam/add_105 (9.22k/9.22k flops)
  training/Adam/add_104 (9.22k/9.22k flops)
  training/Adam/add_87 (9.22k/9.22k flops)
  training/Adam/add_103 (9.22k/9.22k flops)
  training/Adam/sub_22 (9.22k/9.22k flops)
  training/Adam/add_86 (9.22k/9.22k flops)
  training/Adam/add_85 (9.22k/9.22k flops)
  training/Adam/mul_64 (9.22k/9.22k flops)
  training/Adam/mul_63 (9.22k/9.22k flops)
  training/Adam/sub_88 (9.22k/9.22k flops)
  training/Adam/sub_106 (9.22k/9.22k flops)
  training/Adam/mul_141 (9.22k/9.22k flops)
  training/Adam/truediv_13 (9.22k/9.22k flops)
  training/Adam/Square_6 (9.22k/9.22k flops)
  training/Adam/mul_62 (9.22k/9.22k flops)
  training/Adam/mul_143 (9.22k/9.22k flops)
  training/Adam/add_37 (9.22k/9.22k flops)
  training/Adam/mul_145 (9.22k/9.22k flops)
  training/Adam/truediv_35 (9.22k/9.22k flops)
  training/Adam/sub_40 (9.22k/9.22k flops)
  training/Adam/mul_144 (9.22k/9.22k flops)
  training/Adam/add_21 (9.22k/9.22k flops)
  training/Adam/add_20 (9.22k/9.22k flops)
  training/Adam/mul_142 (9.22k/9.22k flops)
  training/Adam/add_19 (9.22k/9.22k flops)
  training/Adam/truediv_29 (9.22k/9.22k flops)
  training/Adam/mul_61 (9.22k/9.22k flops)
  loss/lambda_1_loss/add_6 (8.45k/8.45k flops)
  loss/lambda_1_loss/truediv_1 (8.45k/8.45k flops)
  loss/lambda_1_loss/sub_7 (8.45k/8.45k flops)
  loss/lambda_1_loss/mul_6 (8.45k/8.45k flops)
  fire4/expand1x1/random_uniform (4.10k/8.19k flops)
    fire4/expand1x1/random_uniform/mul (4.10k/4.10k flops)
    fire4/expand1x1/random_uniform/sub (1/1 flops)
  fire5/expand1x1/random_uniform (4.10k/8.19k flops)
    fire5/expand1x1/random_uniform/mul (4.10k/4.10k flops)
    fire5/expand1x1/random_uniform/sub (1/1 flops)
  fire4/squeeze1x1/random_uniform (4.10k/8.19k flops)
    fire4/squeeze1x1/random_uniform/mul (4.10k/4.10k flops)
    fire4/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/Square_20 (8.19k/8.19k flops)
  training/Adam/truediv_21 (8.19k/8.19k flops)
  training/Adam/mul_103 (8.19k/8.19k flops)
  training/Adam/mul_102 (8.19k/8.19k flops)
  training/Adam/mul_101 (8.19k/8.19k flops)
  training/Adam/sub_64 (8.19k/8.19k flops)
  training/Adam/add_63 (8.19k/8.19k flops)
  training/Adam/clip_by_value_17 (4.10k/8.19k flops)
    training/Adam/clip_by_value_17/Minimum (4.10k/4.10k flops)
  training/Adam/clip_by_value_15 (4.10k/8.19k flops)
    training/Adam/clip_by_value_15/Minimum (4.10k/4.10k flops)
  training/Adam/mul_104 (8.19k/8.19k flops)
  training/Adam/mul_105 (8.19k/8.19k flops)
  training/Adam/clip_by_value_23 (4.10k/8.19k flops)
    training/Adam/clip_by_value_23/Minimum (4.10k/4.10k flops)
  training/Adam/add_61 (8.19k/8.19k flops)
  training/Adam/add_62 (8.19k/8.19k flops)
  model_1/fire6/squeeze1x1/BiasAdd (8.11k/8.11k flops)
  model_1/fire7/squeeze1x1/BiasAdd (8.11k/8.11k flops)
  training/Adam/gradients/AddN_12 (8.11k/8.11k flops)
  training/Adam/gradients/AddN_13 (8.11k/8.11k flops)
  training/Adam/gradients/model_1/fire7/squeeze1x1/BiasAdd_grad/BiasAddGrad (8.06k/8.06k flops)
  training/Adam/gradients/model_1/fire6/squeeze1x1/BiasAdd_grad/BiasAddGrad (8.06k/8.06k flops)
  training/Adam/gradients/AddN_8 (5.07k/5.07k flops)
  DetectionLayer/BiasAdd (5.07k/5.07k flops)
  training/Adam/gradients/DetectionLayer/BiasAdd_grad/BiasAddGrad (5.04k/5.04k flops)
  fire3/squeeze1x1/random_uniform (2.05k/4.10k flops)
    fire3/squeeze1x1/random_uniform/mul (2.05k/2.05k flops)
    fire3/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_9 (2.05k/4.10k flops)
    training/Adam/clip_by_value_9/Minimum (2.05k/2.05k flops)
  training/Adam/mul_73 (4.10k/4.10k flops)
  training/Adam/mul_85 (4.10k/4.10k flops)
  training/Adam/mul_112 (4.10k/4.10k flops)
  training/Adam/mul_113 (4.10k/4.10k flops)
  training/Adam/mul_114 (4.10k/4.10k flops)
  training/Adam/mul_115 (4.10k/4.10k flops)
  training/Adam/Square_22 (4.10k/4.10k flops)
  training/Adam/Square_16 (4.10k/4.10k flops)
  training/Adam/Square_14 (4.10k/4.10k flops)
  training/Adam/sub_52 (4.10k/4.10k flops)
  training/Adam/sub_46 (4.10k/4.10k flops)
  training/Adam/add_69 (4.10k/4.10k flops)
  training/Adam/mul_84 (4.10k/4.10k flops)
  training/Adam/mul_83 (4.10k/4.10k flops)
  training/Adam/mul_82 (4.10k/4.10k flops)
  training/Adam/mul_81 (4.10k/4.10k flops)
  training/Adam/mul_75 (4.10k/4.10k flops)
  training/Adam/mul_71 (4.10k/4.10k flops)
  training/Adam/mul_72 (4.10k/4.10k flops)
  training/Adam/mul_74 (4.10k/4.10k flops)
  training/Adam/sub_70 (4.10k/4.10k flops)
  training/Adam/add_68 (4.10k/4.10k flops)
  training/Adam/add_67 (4.10k/4.10k flops)
  training/Adam/add_51 (4.10k/4.10k flops)
  training/Adam/add_50 (4.10k/4.10k flops)
  training/Adam/add_49 (4.10k/4.10k flops)
  training/Adam/add_45 (4.10k/4.10k flops)
  training/Adam/add_43 (4.10k/4.10k flops)
  training/Adam/add_44 (4.10k/4.10k flops)
  training/Adam/truediv_23 (4.10k/4.10k flops)
  training/Adam/truediv_17 (4.10k/4.10k flops)
  training/Adam/truediv_15 (4.10k/4.10k flops)
  training/Adam/mul_111 (4.10k/4.10k flops)
  conv1/random_uniform (1.73k/3.46k flops)
    conv1/random_uniform/mul (1.73k/1.73k flops)
    conv1/random_uniform/sub (1/1 flops)
  training/Adam/clip_by_value_1 (1.73k/3.46k flops)
    training/Adam/clip_by_value_1/Minimum (1.73k/1.73k flops)
  training/Adam/gradients/AddN_7 (3.38k/3.38k flops)
  fire2/expand1x1/random_uniform (1.02k/2.05k flops)
    fire2/expand1x1/random_uniform/mul (1.02k/1.02k flops)
    fire2/expand1x1/random_uniform/sub (1/1 flops)
  fire3/expand1x1/random_uniform (1.02k/2.05k flops)
    fire3/expand1x1/random_uniform/mul (1.02k/1.02k flops)
    fire3/expand1x1/random_uniform/sub (1/1 flops)
  fire2/squeeze1x1/random_uniform (1.02k/2.05k flops)
    fire2/squeeze1x1/random_uniform/mul (1.02k/1.02k flops)
    fire2/squeeze1x1/random_uniform/sub (1/1 flops)
  training/Adam/truediv_9 (2.05k/2.05k flops)
  training/Adam/mul_45 (2.05k/2.05k flops)
  training/Adam/mul_44 (2.05k/2.05k flops)
  training/Adam/mul_43 (2.05k/2.05k flops)
  training/Adam/clip_by_value_5 (1.02k/2.05k flops)
    training/Adam/clip_by_value_5/Minimum (1.02k/1.02k flops)
  training/Adam/mul_42 (2.05k/2.05k flops)
  training/Adam/mul_41 (2.05k/2.05k flops)
  training/Adam/sub_28 (2.05k/2.05k flops)
  training/Adam/Square_8 (2.05k/2.05k flops)
  training/Adam/clip_by_value_11 (1.02k/2.05k flops)
    training/Adam/clip_by_value_11/Minimum (1.02k/1.02k flops)
  training/Adam/add_27 (2.05k/2.05k flops)
  training/Adam/add_26 (2.05k/2.05k flops)
  training/Adam/add_25 (2.05k/2.05k flops)
  training/Adam/clip_by_value_3 (1.02k/2.05k flops)
    training/Adam/clip_by_value_3/Minimum (1.02k/1.02k flops)
  training/Adam/Square (1.73k/1.73k flops)
  training/Adam/add_1 (1.73k/1.73k flops)
  training/Adam/sub_4 (1.73k/1.73k flops)
  training/Adam/mul_1 (1.73k/1.73k flops)
  training/Adam/add_2 (1.73k/1.73k flops)
  training/Adam/truediv_1 (1.73k/1.73k flops)
  training/Adam/mul_2 (1.73k/1.73k flops)
  training/Adam/mul_3 (1.73k/1.73k flops)
  training/Adam/mul_4 (1.73k/1.73k flops)
  training/Adam/mul_5 (1.73k/1.73k flops)
  training/Adam/add_3 (1.73k/1.73k flops)
  loss/lambda_1_loss/cond/add_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Exp_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/add_5 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Minimum_grad/LessEqual (1.69k/1.69k flops)
  loss/lambda_1_loss/mul (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_1_grad/mul (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_1_grad/mul_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_5 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_grad/mul (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_grad/mul_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_9 (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/add (1.69k/1.69k flops)
  loss/lambda_1_loss/mul_15 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/div_1_grad/Neg (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/div_1_grad/RealDiv (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/add_2 (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/mul_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/cond/mul_2 (1.69k/1.69k flops)
  loss/lambda_1_loss/mul_14 (1.69k/1.69k flops)
  loss/lambda_1_loss/div (1.69k/1.69k flops)
  loss/lambda_1_loss/div_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/div_3 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Maximum_grad/GreaterEqual (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_9_grad/Neg (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_2_grad/Neg (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_1_grad/Neg (1.69k/1.69k flops)
  loss/lambda_1_loss/Maximum (1.69k/1.69k flops)
  loss/lambda_1_loss/Maximum_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_10_grad/Neg (1.69k/1.69k flops)
  loss/lambda_1_loss/Minimum (1.69k/1.69k flops)
  loss/lambda_1_loss/Square (1.69k/1.69k flops)
  loss/lambda_1_loss/Square_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/sub (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_1 (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_10 (1.69k/1.69k flops)
  loss/lambda_1_loss/add (1.69k/1.69k flops)
  loss/lambda_1_loss/add_2 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/Maximum_1_grad/GreaterEqual (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_14_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/add_1 (1.69k/1.69k flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_15_grad/mul (1.69k/1.69k flops)
  loss/lambda_1_loss/sub_2 (1.69k/1.69k flops)
  training/Adam/gradients/AddN_6 (1.69k/1.69k flops)
  training/Adam/gradients/AddN_5 (1.69k/1.69k flops)
  loss/lambda_1_loss/Sum_3 (1.69k/1.69k flops)
  loss/lambda_1_loss/Sum_4 (1.69k/1.69k flops)
  training/Adam/add_8 (1.02k/1.02k flops)
  training/Adam/mul_21 (1.02k/1.02k flops)
  training/Adam/mul_25 (1.02k/1.02k flops)
  training/Adam/mul_24 (1.02k/1.02k flops)
  training/Adam/mul_22 (1.02k/1.02k flops)
  training/Adam/mul_23 (1.02k/1.02k flops)
  training/Adam/add_33 (1.02k/1.02k flops)
  training/Adam/add_9 (1.02k/1.02k flops)
  training/Adam/add_7 (1.02k/1.02k flops)
  training/Adam/truediv_5 (1.02k/1.02k flops)
  training/Adam/add_32 (1.02k/1.02k flops)
  training/Adam/add_31 (1.02k/1.02k flops)
  training/Adam/truediv_3 (1.02k/1.02k flops)
  training/Adam/truediv_11 (1.02k/1.02k flops)
  training/Adam/add_15 (1.02k/1.02k flops)
  training/Adam/add_14 (1.02k/1.02k flops)
  training/Adam/add_13 (1.02k/1.02k flops)
  training/Adam/mul_11 (1.02k/1.02k flops)
  training/Adam/mul_12 (1.02k/1.02k flops)
  training/Adam/mul_13 (1.02k/1.02k flops)
  training/Adam/sub_34 (1.02k/1.02k flops)
  training/Adam/sub_16 (1.02k/1.02k flops)
  training/Adam/mul_15 (1.02k/1.02k flops)
  training/Adam/Square_10 (1.02k/1.02k flops)
  training/Adam/mul_51 (1.02k/1.02k flops)
  training/Adam/mul_52 (1.02k/1.02k flops)
  training/Adam/mul_53 (1.02k/1.02k flops)
  training/Adam/mul_54 (1.02k/1.02k flops)
  training/Adam/mul_55 (1.02k/1.02k flops)
  training/Adam/sub_10 (1.02k/1.02k flops)
  training/Adam/Square_2 (1.02k/1.02k flops)
  training/Adam/Square_4 (1.02k/1.02k flops)
  training/Adam/mul_14 (1.02k/1.02k flops)
  loss/lambda_1_loss/sub_11 (845/845 flops)
  loss/lambda_1_loss/truediv (845/845 flops)
  loss/lambda_1_loss/sub_8 (845/845 flops)
  loss/lambda_1_loss/sub_3 (845/845 flops)
  loss/lambda_1_loss/mul_9 (845/845 flops)
  loss/lambda_1_loss/mul_12 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/RealDiv_2 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/RealDiv_1 (845/845 flops)
  training/Adam/gradients/AddN_4 (845/845 flops)
  loss/lambda_1_loss/mul_11 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/RealDiv (845/845 flops)
  loss/lambda_1_loss/mul_1 (845/845 flops)
  loss/lambda_1_loss/add_8 (845/845 flops)
  loss/lambda_1_loss/add_7 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_2_grad/mul_1 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/Square_2_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul (845/845 flops)
  loss/lambda_1_loss/add_3 (845/845 flops)
  loss/lambda_1_loss/mul_10 (845/845 flops)
  loss/lambda_1_loss/Square_2 (845/845 flops)
  loss/lambda_1_loss/Less_1 (845/845 flops)
  loss/lambda_1_loss/Less (845/845 flops)
  loss/lambda_1_loss/Greater_4 (845/845 flops)
  loss/lambda_1_loss/Greater_3 (845/845 flops)
  loss/lambda_1_loss/Greater_2 (845/845 flops)
  loss/lambda_1_loss/Greater_1 (845/845 flops)
  loss/lambda_1_loss/Greater (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_1_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_3_grad/mul_1 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_3_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_4_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_11_grad/Neg (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/sub_3_grad/Neg (845/845 flops)
  loss/lambda_1_loss/mul_5 (845/845 flops)
  loss/lambda_1_loss/mul_13 (845/845 flops)
  loss/lambda_1_loss/mul_8 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_1_grad/mul_1 (845/845 flops)
  loss/lambda_1_loss/mul_4 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_17_grad/mul (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_16_grad/mul (845/845 flops)
  loss/lambda_1_loss/mul_3 (845/845 flops)
  loss/lambda_1_loss/mul_2 (845/845 flops)
  loss/lambda_1_loss/mul_18 (845/845 flops)
  loss/lambda_1_loss/mul_17 (845/845 flops)
  loss/lambda_1_loss/mul_16 (845/845 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_grad/Neg (845/845 flops)
  loss/lambda_1_loss/Sum_6 (844/844 flops)
  loss/lambda_1_loss/Sum (844/844 flops)
  loss/lambda_1_loss/Sum_1 (844/844 flops)
  loss/lambda_1_loss/Sum_2 (844/844 flops)
  loss/lambda_1_loss/Sum_5 (844/844 flops)
  loss/lambda_1_loss/Sum_8 (844/844 flops)
  training/Adam/clip_by_value_44 (256/512 flops)
    training/Adam/clip_by_value_44/Minimum (256/256 flops)
  training/Adam/clip_by_value_42 (256/512 flops)
    training/Adam/clip_by_value_42/Minimum (256/256 flops)
  training/Adam/clip_by_value_48 (256/512 flops)
    training/Adam/clip_by_value_48/Minimum (256/256 flops)
  training/Adam/clip_by_value_50 (256/512 flops)
    training/Adam/clip_by_value_50/Minimum (256/256 flops)
  training/Adam/clip_by_value_30 (192/384 flops)
    training/Adam/clip_by_value_30/Minimum (192/192 flops)
  training/Adam/clip_by_value_38 (192/384 flops)
    training/Adam/clip_by_value_38/Minimum (192/192 flops)
  training/Adam/clip_by_value_36 (192/384 flops)
    training/Adam/clip_by_value_36/Minimum (192/192 flops)
  training/Adam/clip_by_value_32 (192/384 flops)
    training/Adam/clip_by_value_32/Minimum (192/192 flops)
  training/Adam/mul_208 (256/256 flops)
  training/Adam/mul_216 (256/256 flops)
  training/Adam/mul_207 (256/256 flops)
  training/Adam/mul_206 (256/256 flops)
  training/Adam/sub_127 (256/256 flops)
  training/Adam/sub_133 (256/256 flops)
  training/Adam/Square_41 (256/256 flops)
  training/Adam/Square_43 (256/256 flops)
  training/Adam/sub_151 (256/256 flops)
  training/Adam/Square_47 (256/256 flops)
  training/Adam/Square_49 (256/256 flops)
  training/Adam/clip_by_value_18 (128/256 flops)
    training/Adam/clip_by_value_18/Minimum (128/128 flops)
  training/Adam/clip_by_value_20 (128/256 flops)
    training/Adam/clip_by_value_20/Minimum (128/128 flops)
  training/Adam/clip_by_value_24 (128/256 flops)
    training/Adam/clip_by_value_24/Minimum (128/128 flops)
  training/Adam/clip_by_value_26 (128/256 flops)
    training/Adam/clip_by_value_26/Minimum (128/128 flops)
  training/Adam/add_124 (256/256 flops)
  training/Adam/mul_249 (256/256 flops)
  training/Adam/mul_238 (256/256 flops)
  training/Adam/mul_237 (256/256 flops)
  training/Adam/mul_236 (256/256 flops)
  training/Adam/mul_239 (256/256 flops)
  training/Adam/mul_240 (256/256 flops)
  training/Adam/mul_246 (256/256 flops)
  training/Adam/mul_247 (256/256 flops)
  training/Adam/mul_248 (256/256 flops)
  training/Adam/mul_209 (256/256 flops)
  training/Adam/mul_250 (256/256 flops)
  training/Adam/mul_220 (256/256 flops)
  training/Adam/mul_219 (256/256 flops)
  training/Adam/mul_218 (256/256 flops)
  training/Adam/mul_217 (256/256 flops)
  training/Adam/sub_145 (256/256 flops)
  training/Adam/mul_210 (256/256 flops)
  training/Adam/add_143 (256/256 flops)
  training/Adam/add_132 (256/256 flops)
  training/Adam/add_150 (256/256 flops)
  training/Adam/add_126 (256/256 flops)
  training/Adam/add_149 (256/256 flops)
  training/Adam/add_148 (256/256 flops)
  training/Adam/add_144 (256/256 flops)
  training/Adam/add_142 (256/256 flops)
  training/Adam/add_125 (256/256 flops)
  training/Adam/add_131 (256/256 flops)
  training/Adam/add_130 (256/256 flops)
  training/Adam/truediv_42 (256/256 flops)
  training/Adam/truediv_44 (256/256 flops)
  training/Adam/truediv_48 (256/256 flops)
  training/Adam/truediv_50 (256/256 flops)
  training/Adam/mul_180 (192/192 flops)
  training/Adam/mul_188 (192/192 flops)
  training/Adam/mul_186 (192/192 flops)
  training/Adam/mul_146 (192/192 flops)
  training/Adam/mul_147 (192/192 flops)
  training/Adam/mul_187 (192/192 flops)
  training/Adam/mul_148 (192/192 flops)
  training/Adam/mul_190 (192/192 flops)
  training/Adam/mul_149 (192/192 flops)
  training/Adam/mul_150 (192/192 flops)
  training/Adam/mul_179 (192/192 flops)
  training/Adam/mul_178 (192/192 flops)
  training/Adam/mul_177 (192/192 flops)
  training/Adam/mul_176 (192/192 flops)
  training/Adam/mul_156 (192/192 flops)
  training/Adam/mul_157 (192/192 flops)
  training/Adam/mul_158 (192/192 flops)
  training/Adam/mul_159 (192/192 flops)
  training/Adam/mul_160 (192/192 flops)
  training/Adam/Square_37 (192/192 flops)
  training/Adam/Square_35 (192/192 flops)
  training/Adam/Square_31 (192/192 flops)
  training/Adam/sub_115 (192/192 flops)
  training/Adam/sub_109 (192/192 flops)
  training/Adam/Square_29 (192/192 flops)
  training/Adam/add_114 (192/192 flops)
  training/Adam/add_112 (192/192 flops)
  training/Adam/add_94 (192/192 flops)
  training/Adam/add_108 (192/192 flops)
  training/Adam/add_90 (192/192 flops)
  training/Adam/add_89 (192/192 flops)
  training/Adam/truediv_38 (192/192 flops)
  training/Adam/add_88 (192/192 flops)
  training/Adam/truediv_36 (192/192 flops)
  training/Adam/add_113 (192/192 flops)
  training/Adam/truediv_32 (192/192 flops)
  training/Adam/add_107 (192/192 flops)
  training/Adam/add_106 (192/192 flops)
  training/Adam/truediv_30 (192/192 flops)
  training/Adam/add_95 (192/192 flops)
  training/Adam/add_96 (192/192 flops)
  training/Adam/sub_91 (192/192 flops)
  training/Adam/sub_97 (192/192 flops)
  training/Adam/mul_189 (192/192 flops)
  training/Adam/mul_90 (128/128 flops)
  training/Adam/mul_89 (128/128 flops)
  training/Adam/clip_by_value_46 (64/128 flops)
    training/Adam/clip_by_value_46/Minimum (64/64 flops)
  training/Adam/Square_23 (128/128 flops)
  training/Adam/Square_25 (128/128 flops)
  training/Adam/clip_by_value_40 (64/128 flops)
    training/Adam/clip_by_value_40/Minimum (64/64 flops)
  training/Adam/mul_88 (128/128 flops)
  training/Adam/add_78 (128/128 flops)
  training/Adam/add_77 (128/128 flops)
  training/Adam/add_76 (128/128 flops)
  training/Adam/add_72 (128/128 flops)
  training/Adam/add_71 (128/128 flops)
  training/Adam/mul_87 (128/128 flops)
  training/Adam/Square_19 (128/128 flops)
  training/Adam/Square_17 (128/128 flops)
  training/Adam/mul_86 (128/128 flops)
  training/Adam/add_70 (128/128 flops)
  training/Adam/truediv_18 (128/128 flops)
  training/Adam/mul_119 (128/128 flops)
  training/Adam/truediv_20 (128/128 flops)
  training/Adam/sub_61 (128/128 flops)
  training/Adam/clip_by_value_2 (64/128 flops)
    training/Adam/clip_by_value_2/Minimum (64/64 flops)
  training/Adam/add_53 (128/128 flops)
  training/Adam/sub_79 (128/128 flops)
  training/Adam/mul_116 (128/128 flops)
  training/Adam/add_59 (128/128 flops)
  training/Adam/mul_117 (128/128 flops)
  training/Adam/mul_118 (128/128 flops)
  training/Adam/mul_97 (128/128 flops)
  training/Adam/add_54 (128/128 flops)
  training/Adam/mul_120 (128/128 flops)
  training/Adam/mul_130 (128/128 flops)
  training/Adam/add_58 (128/128 flops)
  training/Adam/mul_129 (128/128 flops)
  training/Adam/mul_128 (128/128 flops)
  training/Adam/mul_127 (128/128 flops)
  training/Adam/mul_126 (128/128 flops)
  training/Adam/sub_73 (128/128 flops)
  training/Adam/add_60 (128/128 flops)
  training/Adam/mul_100 (128/128 flops)
  training/Adam/truediv_26 (128/128 flops)
  training/Adam/truediv_24 (128/128 flops)
  training/Adam/clip_by_value_8 (64/128 flops)
    training/Adam/clip_by_value_8/Minimum (64/64 flops)
  training/Adam/sub_55 (128/128 flops)
  training/Adam/add_52 (128/128 flops)
  training/Adam/clip_by_value_12 (64/128 flops)
    training/Adam/clip_by_value_12/Minimum (64/64 flops)
  training/Adam/clip_by_value_6 (64/128 flops)
    training/Adam/clip_by_value_6/Minimum (64/64 flops)
  training/Adam/mul_99 (128/128 flops)
  training/Adam/mul_98 (128/128 flops)
  training/Adam/clip_by_value_14 (64/128 flops)
    training/Adam/clip_by_value_14/Minimum (64/64 flops)
  training/Adam/mul_96 (128/128 flops)
  training/Adam/clip_by_value_28 (48/96 flops)
    training/Adam/clip_by_value_28/Minimum (48/48 flops)
  training/Adam/clip_by_value_34 (48/96 flops)
    training/Adam/clip_by_value_34/Minimum (48/48 flops)
  training/Adam/truediv_6 (64/64 flops)
  training/Adam/truediv_14 (64/64 flops)
  training/Adam/truediv_8 (64/64 flops)
  training/Adam/mul_30 (64/64 flops)
  training/Adam/mul_36 (64/64 flops)
  training/Adam/clip_by_value_22 (32/64 flops)
    training/Adam/clip_by_value_22/Minimum (32/32 flops)
  training/Adam/truediv_46 (64/64 flops)
  training/Adam/truediv_12 (64/64 flops)
  training/Adam/truediv_2 (64/64 flops)
  training/Adam/mul_29 (64/64 flops)
  training/Adam/mul_28 (64/64 flops)
  training/Adam/mul_27 (64/64 flops)
  training/Adam/truediv_40 (64/64 flops)
  training/Adam/mul_26 (64/64 flops)
  training/Adam/mul_68 (64/64 flops)
  training/Adam/mul_9 (64/64 flops)
  training/Adam/sub_121 (64/64 flops)
  training/Adam/sub_139 (64/64 flops)
  training/Adam/add_35 (64/64 flops)
  training/Adam/sub_19 (64/64 flops)
  training/Adam/sub_25 (64/64 flops)
  training/Adam/sub_37 (64/64 flops)
  training/Adam/mul_8 (64/64 flops)
  training/Adam/clip_by_value_16 (32/64 flops)
    training/Adam/clip_by_value_16/Minimum (32/32 flops)
  training/Adam/sub_43 (64/64 flops)
  training/Adam/mul_70 (64/64 flops)
  training/Adam/mul_7 (64/64 flops)
  training/Adam/mul_69 (64/64 flops)
  training/Adam/mul_37 (64/64 flops)
  training/Adam/mul_67 (64/64 flops)
  training/Adam/mul_66 (64/64 flops)
  training/Adam/mul_60 (64/64 flops)
  training/Adam/mul_6 (64/64 flops)
  training/Adam/mul_59 (64/64 flops)
  training/Adam/mul_58 (64/64 flops)
  training/Adam/mul_57 (64/64 flops)
  training/Adam/mul_56 (64/64 flops)
  training/Adam/mul_40 (64/64 flops)
  training/Adam/mul_39 (64/64 flops)
  training/Adam/sub_7 (64/64 flops)
  training/Adam/mul_38 (64/64 flops)
  training/Adam/Square_39 (64/64 flops)
  training/Adam/mul_227 (64/64 flops)
  training/Adam/mul_226 (64/64 flops)
  training/Adam/add_18 (64/64 flops)
  training/Adam/add_17 (64/64 flops)
  training/Adam/add_16 (64/64 flops)
  training/Adam/Square_7 (64/64 flops)
  training/Adam/add_138 (64/64 flops)
  training/Adam/add_137 (64/64 flops)
  training/Adam/add_136 (64/64 flops)
  training/Adam/mul_200 (64/64 flops)
  training/Adam/mul_199 (64/64 flops)
  training/Adam/mul_198 (64/64 flops)
  training/Adam/add_5 (64/64 flops)
  training/Adam/mul_197 (64/64 flops)
  training/Adam/mul_196 (64/64 flops)
  training/Adam/mul_10 (64/64 flops)
  training/Adam/Square_1 (64/64 flops)
  training/Adam/Square_11 (64/64 flops)
  training/Adam/add_120 (64/64 flops)
  training/Adam/add_119 (64/64 flops)
  training/Adam/Square_13 (64/64 flops)
  training/Adam/add_118 (64/64 flops)
  training/Adam/Square_5 (64/64 flops)
  training/Adam/add_6 (64/64 flops)
  training/Adam/Square_45 (64/64 flops)
  training/Adam/add_4 (64/64 flops)
  training/Adam/add_34 (64/64 flops)
  training/Adam/mul_229 (64/64 flops)
  training/Adam/add_22 (64/64 flops)
  training/Adam/mul_230 (64/64 flops)
  training/Adam/add_40 (64/64 flops)
  training/Adam/add_23 (64/64 flops)
  training/Adam/add_36 (64/64 flops)
  training/Adam/mul_228 (64/64 flops)
  training/Adam/add_41 (64/64 flops)
  training/Adam/add_42 (64/64 flops)
  training/Adam/add_24 (64/64 flops)
  training/Adam/clip_by_value_52 (30/60 flops)
    training/Adam/clip_by_value_52/Minimum (30/30 flops)
  training/Adam/truediv_28 (48/48 flops)
  training/Adam/add_101 (48/48 flops)
  training/Adam/mul_138 (48/48 flops)
  training/Adam/sub_103 (48/48 flops)
  training/Adam/mul_140 (48/48 flops)
  training/Adam/add_100 (48/48 flops)
  training/Adam/mul_166 (48/48 flops)
  training/Adam/sub_85 (48/48 flops)
  training/Adam/mul_139 (48/48 flops)
  training/Adam/mul_137 (48/48 flops)
  training/Adam/mul_168 (48/48 flops)
  training/Adam/mul_169 (48/48 flops)
  training/Adam/add_84 (48/48 flops)
  training/Adam/add_102 (48/48 flops)
  training/Adam/mul_167 (48/48 flops)
  training/Adam/add_83 (48/48 flops)
  training/Adam/add_82 (48/48 flops)
  training/Adam/Square_33 (48/48 flops)
  training/Adam/mul_136 (48/48 flops)
  training/Adam/truediv_34 (48/48 flops)
  training/Adam/mul_170 (48/48 flops)
  training/Adam/Square_27 (48/48 flops)
  training/Adam/sub_67 (32/32 flops)
  training/Adam/mul_79 (32/32 flops)
  training/Adam/truediv_16 (32/32 flops)
  training/Adam/add_64 (32/32 flops)
  training/Adam/Square_15 (32/32 flops)
  training/Adam/add_66 (32/32 flops)
  training/Adam/Square_21 (32/32 flops)
  training/Adam/mul_107 (32/32 flops)
  training/Adam/mul_106 (32/32 flops)
  training/Adam/mul_108 (32/32 flops)
  training/Adam/mul_80 (32/32 flops)
  training/Adam/mul_76 (32/32 flops)
  training/Adam/mul_77 (32/32 flops)
  training/Adam/mul_78 (32/32 flops)
  training/Adam/sub_49 (32/32 flops)
  training/Adam/add_47 (32/32 flops)
  training/Adam/add_48 (32/32 flops)
  training/Adam/add_65 (32/32 flops)
  training/Adam/mul_110 (32/32 flops)
  training/Adam/clip_by_value_10 (16/32 flops)
    training/Adam/clip_by_value_10/Minimum (16/16 flops)
  training/Adam/truediv_22 (32/32 flops)
  training/Adam/clip_by_value_4 (16/32 flops)
    training/Adam/clip_by_value_4/Minimum (16/16 flops)
  training/Adam/add_46 (32/32 flops)
  training/Adam/mul_109 (32/32 flops)
  training/Adam/mul_258 (30/30 flops)
  training/Adam/sub_157 (30/30 flops)
  training/Adam/mul_257 (30/30 flops)
  training/Adam/mul_259 (30/30 flops)
  training/Adam/add_156 (30/30 flops)
  training/Adam/add_155 (30/30 flops)
  training/Adam/add_154 (30/30 flops)
  training/Adam/mul_260 (30/30 flops)
  training/Adam/mul_256 (30/30 flops)
  training/Adam/truediv_52 (30/30 flops)
  training/Adam/Square_51 (30/30 flops)
  loss/lambda_1_loss/sub_4 (20/20 flops)
  loss/lambda_1_loss/add_4 (20/20 flops)
  loss/lambda_1_loss/div_2 (20/20 flops)
  training/Adam/add_10 (16/16 flops)
  training/Adam/add_11 (16/16 flops)
  training/Adam/mul_16 (16/16 flops)
  training/Adam/Square_3 (16/16 flops)
  training/Adam/add_30 (16/16 flops)
  training/Adam/add_29 (16/16 flops)
  training/Adam/mul_46 (16/16 flops)
  training/Adam/mul_47 (16/16 flops)
  training/Adam/mul_48 (16/16 flops)
  training/Adam/mul_49 (16/16 flops)
  training/Adam/mul_50 (16/16 flops)
  training/Adam/mul_20 (16/16 flops)
  training/Adam/Square_9 (16/16 flops)
  training/Adam/mul_17 (16/16 flops)
  training/Adam/add_28 (16/16 flops)
  training/Adam/mul_19 (16/16 flops)
  training/Adam/add_12 (16/16 flops)
  training/Adam/truediv_10 (16/16 flops)
  training/Adam/truediv_4 (16/16 flops)
  training/Adam/mul_18 (16/16 flops)
  training/Adam/sub_31 (16/16 flops)
  training/Adam/sub_13 (16/16 flops)
  loss/lambda_1_loss/mul_7 (10/10 flops)
  training/Adam/clip_by_value (1/2 flops)
    training/Adam/clip_by_value/Minimum (1/1 flops)
  training/Adam/sub_60 (1/1 flops)
  training/Adam/sub_56 (1/1 flops)
  training/Adam/sub_33 (1/1 flops)
  training/Adam/sub_57 (1/1 flops)
  training/Adam/sub_62 (1/1 flops)
  training/Adam/sub_6 (1/1 flops)
  training/Adam/sub_59 (1/1 flops)
  training/Adam/sub_45 (1/1 flops)
  training/Adam/sub_146 (1/1 flops)
  training/Adam/sub_35 (1/1 flops)
  training/Adam/sub_36 (1/1 flops)
  training/Adam/sub_38 (1/1 flops)
  training/Adam/sub_39 (1/1 flops)
  training/Adam/sub_41 (1/1 flops)
  training/Adam/sub_42 (1/1 flops)
  training/Adam/sub_44 (1/1 flops)
  training/Adam/sub_54 (1/1 flops)
  training/Adam/gradients/AddN_3 (1/1 flops)
  training/Adam/sub_47 (1/1 flops)
  training/Adam/sub_48 (1/1 flops)
  training/Adam/sub_5 (1/1 flops)
  training/Adam/sub_50 (1/1 flops)
  training/Adam/sub_51 (1/1 flops)
  training/Adam/gradients/AddN_2 (1/1 flops)
  training/Adam/sub_53 (1/1 flops)
  loss/lambda_1_loss/SparseSoftmaxCrossEntropyWithLogits/add (1/1 flops)
  training/Adam/sub_92 (1/1 flops)
  training/Adam/sub_93 (1/1 flops)
  training/Adam/sub_95 (1/1 flops)
  training/Adam/sub_96 (1/1 flops)
  training/Adam/sub_98 (1/1 flops)
  training/Adam/sub_99 (1/1 flops)
  training/Adam/truediv (1/1 flops)
  training/Adam/gradients/AddN_1 (1/1 flops)
  training/Adam/gradients/AddN (1/1 flops)
  loss/lambda_1_loss/SparseSoftmaxCrossEntropyWithLogits/sub (1/1 flops)
  training/Adam/sub_90 (1/1 flops)
  training/Adam/mul (1/1 flops)
  loss/lambda_1_loss/NotEqual (1/1 flops)
  loss/lambda_1_loss/Mean_2 (1/1 flops)
  loss/lambda_1_loss/Mean_1 (1/1 flops)
  loss/lambda_1_loss/Mean (1/1 flops)
  loss/lambda_1_loss/Less_3 (1/1 flops)
  loss/lambda_1_loss/Less_2 (1/1 flops)
  loss/lambda_1_loss/AssignAdd_1 (1/1 flops)
  loss/lambda_1_loss/AssignAdd (1/1 flops)
  training/Adam/sub_78 (1/1 flops)
  training/Adam/add (1/1 flops)
  training/Adam/sub_65 (1/1 flops)
  training/Adam/sub_66 (1/1 flops)
  training/Adam/sub_68 (1/1 flops)
  training/Adam/sub_69 (1/1 flops)
  training/Adam/sub_71 (1/1 flops)
  training/Adam/sub_72 (1/1 flops)
  training/Adam/sub_74 (1/1 flops)
  training/Adam/sub_75 (1/1 flops)
  training/Adam/sub_77 (1/1 flops)
  training/Adam/sub_63 (1/1 flops)
  training/Adam/sub_8 (1/1 flops)
  training/Adam/sub_80 (1/1 flops)
  training/Adam/sub_81 (1/1 flops)
  training/Adam/sub_83 (1/1 flops)
  training/Adam/sub_84 (1/1 flops)
  training/Adam/sub_86 (1/1 flops)
  training/Adam/sub_87 (1/1 flops)
  training/Adam/sub_89 (1/1 flops)
  training/Adam/sub_9 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_5 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/RealDiv_1 (1/1 flops)
  training/Adam/AssignAdd (1/1 flops)
  training/Adam/Pow (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/RealDiv (1/1 flops)
  loss/lambda_1_loss/div_12 (1/1 flops)
  loss/lambda_1_loss/div_11 (1/1 flops)
  loss/lambda_1_loss/div_10 (1/1 flops)
  training/Adam/Pow_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_5_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/mul (1/1 flops)
  loss/lambda_1_loss/cond_1/add_6 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/RealDiv_1 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_4 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_3 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_2 (1/1 flops)
  loss/lambda_1_loss/cond_1/add_1 (1/1 flops)
  loss/lambda_1_loss/cond_1/add (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/RealDiv_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_4_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/RealDiv_2 (1/1 flops)
  training/Adam/sub (1/1 flops)
  training/Adam/sub_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/RealDiv_1 (1/1 flops)
  loss/lambda_1_loss/add_9 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_2_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/RealDiv_1 (1/1 flops)
  loss/lambda_1_loss/mul_19 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_9_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/truediv_2_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/mul_grad/Mul (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/mul (1/1 flops)
  training/Adam/gradients/loss/mul_grad/Mul_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/RealDiv_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_8_grad/Neg (1/1 flops)
  training/Adam/sub_101 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/RealDiv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/RealDiv_1 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/RealDiv (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_7_grad/Neg (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/mul (1/1 flops)
  loss/lambda_1_loss/div_9 (1/1 flops)
  loss/lambda_1_loss/truediv_2 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_6_grad/RealDiv_2 (1/1 flops)
  loss/mul (1/1 flops)
  loss/lambda_1_loss/div_8 (1/1 flops)
  loss/lambda_1_loss/div_7 (1/1 flops)
  loss/lambda_1_loss/div_6 (1/1 flops)
  loss/lambda_1_loss/div_5 (1/1 flops)
  loss/lambda_1_loss/div_4 (1/1 flops)
  loss/lambda_1_loss/add_11 (1/1 flops)
  training/Adam/sub_138 (1/1 flops)
  training/Adam/sub_14 (1/1 flops)
  training/Adam/sub_140 (1/1 flops)
  training/Adam/sub_141 (1/1 flops)
  loss/lambda_1_loss/add_13 (1/1 flops)
  training/Adam/sub_143 (1/1 flops)
  training/Adam/sub_144 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/mul_19_grad/mul (1/1 flops)
  training/Adam/sub_147 (1/1 flops)
  loss/lambda_1_loss/add_12 (1/1 flops)
  training/Adam/sub_149 (1/1 flops)
  training/Adam/sub_15 (1/1 flops)
  training/Adam/sub_150 (1/1 flops)
  training/Adam/sub_152 (1/1 flops)
  training/Adam/sub_153 (1/1 flops)
  training/Adam/sub_137 (1/1 flops)
  training/Adam/sub_155 (1/1 flops)
  training/Adam/sub_156 (1/1 flops)
  training/Adam/sub_17 (1/1 flops)
  training/Adam/sub_18 (1/1 flops)
  training/Adam/sub_2 (1/1 flops)
  training/Adam/sub_20 (1/1 flops)
  training/Adam/sub_21 (1/1 flops)
  loss/lambda_1_loss/add_10 (1/1 flops)
  training/Adam/sub_23 (1/1 flops)
  training/Adam/sub_24 (1/1 flops)
  training/Adam/sub_26 (1/1 flops)
  training/Adam/sub_27 (1/1 flops)
  training/Adam/sub_29 (1/1 flops)
  training/Adam/sub_3 (1/1 flops)
  training/Adam/sub_30 (1/1 flops)
  training/Adam/sub_119 (1/1 flops)
  training/Adam/sub_102 (1/1 flops)
  training/Adam/sub_104 (1/1 flops)
  training/Adam/sub_105 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/RealDiv (1/1 flops)
  training/Adam/sub_107 (1/1 flops)
  training/Adam/sub_108 (1/1 flops)
  training/Adam/sub_11 (1/1 flops)
  training/Adam/sub_110 (1/1 flops)
  training/Adam/sub_111 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/div_10_grad/Neg (1/1 flops)
  training/Adam/sub_113 (1/1 flops)
  training/Adam/sub_114 (1/1 flops)
  training/Adam/sub_116 (1/1 flops)
  training/Adam/sub_117 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/Mean_grad/truediv (1/1 flops)
  training/Adam/sub_32 (1/1 flops)
  training/Adam/sub_12 (1/1 flops)
  training/Adam/sub_120 (1/1 flops)
  training/Adam/sub_122 (1/1 flops)
  training/Adam/sub_123 (1/1 flops)
  training/Adam/sub_125 (1/1 flops)
  training/Adam/sub_126 (1/1 flops)
  training/Adam/sub_128 (1/1 flops)
  training/Adam/sub_129 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/Mean_2_grad/truediv (1/1 flops)
  training/Adam/sub_131 (1/1 flops)
  training/Adam/sub_132 (1/1 flops)
  training/Adam/sub_134 (1/1 flops)
  training/Adam/sub_135 (1/1 flops)
  training/Adam/gradients/loss/lambda_1_loss/Mean_2_grad/Maximum (1/1 flops)

======================End of Report==========================
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              0
-min_occurrence             0
-step                       -1
-order_by                   name
-account_type_regexes       _trainable_variables
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     params
-output                     stdout:

==================Model Analysis Report======================
node name | # parameters
_TFProfRoot (--/2.21m params)
  Adam (--/5 params)
    Adam/beta_1 (1, 1/1 params)
    Adam/beta_2 (1, 1/1 params)
    Adam/decay (1, 1/1 params)
    Adam/iterations (1, 1/1 params)
    Adam/lr (1, 1/1 params)
  DetectionLayer (--/15.39k params)
    DetectionLayer/bias (30, 30/30 params)
    DetectionLayer/kernel (1x1x512x30, 15.36k/15.36k params)
  conv1 (--/1.79k params)
    conv1/bias (64, 64/64 params)
    conv1/kernel (3x3x3x64, 1.73k/1.73k params)
  fire2 (--/11.41k params)
    fire2/expand1x1 (--/1.09k params)
      fire2/expand1x1/bias (64, 64/64 params)
      fire2/expand1x1/kernel (1x1x16x64, 1.02k/1.02k params)
    fire2/expand3x3 (--/9.28k params)
      fire2/expand3x3/bias (64, 64/64 params)
      fire2/expand3x3/kernel (3x3x16x64, 9.22k/9.22k params)
    fire2/squeeze1x1 (--/1.04k params)
      fire2/squeeze1x1/bias (16, 16/16 params)
      fire2/squeeze1x1/kernel (1x1x64x16, 1.02k/1.02k params)
  fire3 (--/12.43k params)
    fire3/expand1x1 (--/1.09k params)
      fire3/expand1x1/bias (64, 64/64 params)
      fire3/expand1x1/kernel (1x1x16x64, 1.02k/1.02k params)
    fire3/expand3x3 (--/9.28k params)
      fire3/expand3x3/bias (64, 64/64 params)
      fire3/expand3x3/kernel (3x3x16x64, 9.22k/9.22k params)
    fire3/squeeze1x1 (--/2.06k params)
      fire3/squeeze1x1/bias (16, 16/16 params)
      fire3/squeeze1x1/kernel (1x1x128x16, 2.05k/2.05k params)
  fire4 (--/45.34k params)
    fire4/expand1x1 (--/4.22k params)
      fire4/expand1x1/bias (128, 128/128 params)
      fire4/expand1x1/kernel (1x1x32x128, 4.10k/4.10k params)
    fire4/expand3x3 (--/36.99k params)
      fire4/expand3x3/bias (128, 128/128 params)
      fire4/expand3x3/kernel (3x3x32x128, 36.86k/36.86k params)
    fire4/squeeze1x1 (--/4.13k params)
      fire4/squeeze1x1/bias (32, 32/32 params)
      fire4/squeeze1x1/kernel (1x1x128x32, 4.10k/4.10k params)
  fire5 (--/49.44k params)
    fire5/expand1x1 (--/4.22k params)
      fire5/expand1x1/bias (128, 128/128 params)
      fire5/expand1x1/kernel (1x1x32x128, 4.10k/4.10k params)
    fire5/expand3x3 (--/36.99k params)
      fire5/expand3x3/bias (128, 128/128 params)
      fire5/expand3x3/kernel (3x3x32x128, 36.86k/36.86k params)
    fire5/squeeze1x1 (--/8.22k params)
      fire5/squeeze1x1/bias (32, 32/32 params)
      fire5/squeeze1x1/kernel (1x1x256x32, 8.19k/8.19k params)
  fire6 (--/104.88k params)
    fire6/expand1x1 (--/9.41k params)
      fire6/expand1x1/bias (192, 192/192 params)
      fire6/expand1x1/kernel (1x1x48x192, 9.22k/9.22k params)
    fire6/expand3x3 (--/83.14k params)
      fire6/expand3x3/bias (192, 192/192 params)
      fire6/expand3x3/kernel (3x3x48x192, 82.94k/82.94k params)
    fire6/squeeze1x1 (--/12.34k params)
      fire6/squeeze1x1/bias (48, 48/48 params)
      fire6/squeeze1x1/kernel (1x1x256x48, 12.29k/12.29k params)
  fire7 (--/111.02k params)
    fire7/expand1x1 (--/9.41k params)
      fire7/expand1x1/bias (192, 192/192 params)
      fire7/expand1x1/kernel (1x1x48x192, 9.22k/9.22k params)
    fire7/expand3x3 (--/83.14k params)
      fire7/expand3x3/bias (192, 192/192 params)
      fire7/expand3x3/kernel (3x3x48x192, 82.94k/82.94k params)
    fire7/squeeze1x1 (--/18.48k params)
      fire7/squeeze1x1/bias (48, 48/48 params)
      fire7/squeeze1x1/kernel (1x1x384x48, 18.43k/18.43k params)
  fire8 (--/188.99k params)
    fire8/expand1x1 (--/16.64k params)
      fire8/expand1x1/bias (256, 256/256 params)
      fire8/expand1x1/kernel (1x1x64x256, 16.38k/16.38k params)
    fire8/expand3x3 (--/147.71k params)
      fire8/expand3x3/bias (256, 256/256 params)
      fire8/expand3x3/kernel (3x3x64x256, 147.46k/147.46k params)
    fire8/squeeze1x1 (--/24.64k params)
      fire8/squeeze1x1/bias (64, 64/64 params)
      fire8/squeeze1x1/kernel (1x1x384x64, 24.58k/24.58k params)
  fire9 (--/197.18k params)
    fire9/expand1x1 (--/16.64k params)
      fire9/expand1x1/bias (256, 256/256 params)
      fire9/expand1x1/kernel (1x1x64x256, 16.38k/16.38k params)
    fire9/expand3x3 (--/147.71k params)
      fire9/expand3x3/bias (256, 256/256 params)
      fire9/expand3x3/kernel (3x3x64x256, 147.46k/147.46k params)
    fire9/squeeze1x1 (--/32.83k params)
      fire9/squeeze1x1/bias (64, 64/64 params)
      fire9/squeeze1x1/kernel (1x1x512x64, 32.77k/32.77k params)
  loss (--/2 params)
    loss/lambda_1_loss (--/2 params)
      loss/lambda_1_loss/Variable (1, 1/1 params)
      loss/lambda_1_loss/Variable_1 (1, 1/1 params)
  training (--/1.48m params)
    training/Adam (--/1.48m params)
      training/Adam/Variable (3x3x3x64, 1.73k/1.73k params)
      training/Adam/Variable_1 (64, 64/64 params)
      training/Adam/Variable_10 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_100 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_101 (256, 256/256 params)
      training/Adam/Variable_102 (1x1x512x30, 15.36k/15.36k params)
      training/Adam/Variable_103 (30, 30/30 params)
      training/Adam/Variable_104 (1, 1/1 params)
      training/Adam/Variable_105 (1, 1/1 params)
      training/Adam/Variable_106 (1, 1/1 params)
      training/Adam/Variable_107 (1, 1/1 params)
      training/Adam/Variable_108 (1, 1/1 params)
      training/Adam/Variable_109 (1, 1/1 params)
      training/Adam/Variable_11 (64, 64/64 params)
      training/Adam/Variable_110 (1, 1/1 params)
      training/Adam/Variable_111 (1, 1/1 params)
      training/Adam/Variable_112 (1, 1/1 params)
      training/Adam/Variable_113 (1, 1/1 params)
      training/Adam/Variable_114 (1, 1/1 params)
      training/Adam/Variable_115 (1, 1/1 params)
      training/Adam/Variable_116 (1, 1/1 params)
      training/Adam/Variable_117 (1, 1/1 params)
      training/Adam/Variable_118 (1, 1/1 params)
      training/Adam/Variable_119 (1, 1/1 params)
      training/Adam/Variable_12 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_120 (1, 1/1 params)
      training/Adam/Variable_121 (1, 1/1 params)
      training/Adam/Variable_122 (1, 1/1 params)
      training/Adam/Variable_123 (1, 1/1 params)
      training/Adam/Variable_124 (1, 1/1 params)
      training/Adam/Variable_125 (1, 1/1 params)
      training/Adam/Variable_126 (1, 1/1 params)
      training/Adam/Variable_127 (1, 1/1 params)
      training/Adam/Variable_128 (1, 1/1 params)
      training/Adam/Variable_129 (1, 1/1 params)
      training/Adam/Variable_13 (64, 64/64 params)
      training/Adam/Variable_130 (1, 1/1 params)
      training/Adam/Variable_131 (1, 1/1 params)
      training/Adam/Variable_132 (1, 1/1 params)
      training/Adam/Variable_133 (1, 1/1 params)
      training/Adam/Variable_134 (1, 1/1 params)
      training/Adam/Variable_135 (1, 1/1 params)
      training/Adam/Variable_136 (1, 1/1 params)
      training/Adam/Variable_137 (1, 1/1 params)
      training/Adam/Variable_138 (1, 1/1 params)
      training/Adam/Variable_139 (1, 1/1 params)
      training/Adam/Variable_14 (1x1x128x32, 4.10k/4.10k params)
      training/Adam/Variable_140 (1, 1/1 params)
      training/Adam/Variable_141 (1, 1/1 params)
      training/Adam/Variable_142 (1, 1/1 params)
      training/Adam/Variable_143 (1, 1/1 params)
      training/Adam/Variable_144 (1, 1/1 params)
      training/Adam/Variable_145 (1, 1/1 params)
      training/Adam/Variable_146 (1, 1/1 params)
      training/Adam/Variable_147 (1, 1/1 params)
      training/Adam/Variable_148 (1, 1/1 params)
      training/Adam/Variable_149 (1, 1/1 params)
      training/Adam/Variable_15 (32, 32/32 params)
      training/Adam/Variable_150 (1, 1/1 params)
      training/Adam/Variable_151 (1, 1/1 params)
      training/Adam/Variable_152 (1, 1/1 params)
      training/Adam/Variable_153 (1, 1/1 params)
      training/Adam/Variable_154 (1, 1/1 params)
      training/Adam/Variable_155 (1, 1/1 params)
      training/Adam/Variable_16 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_17 (128, 128/128 params)
      training/Adam/Variable_18 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_19 (128, 128/128 params)
      training/Adam/Variable_2 (1x1x64x16, 1.02k/1.02k params)
      training/Adam/Variable_20 (1x1x256x32, 8.19k/8.19k params)
      training/Adam/Variable_21 (32, 32/32 params)
      training/Adam/Variable_22 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_23 (128, 128/128 params)
      training/Adam/Variable_24 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_25 (128, 128/128 params)
      training/Adam/Variable_26 (1x1x256x48, 12.29k/12.29k params)
      training/Adam/Variable_27 (48, 48/48 params)
      training/Adam/Variable_28 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_29 (192, 192/192 params)
      training/Adam/Variable_3 (16, 16/16 params)
      training/Adam/Variable_30 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_31 (192, 192/192 params)
      training/Adam/Variable_32 (1x1x384x48, 18.43k/18.43k params)
      training/Adam/Variable_33 (48, 48/48 params)
      training/Adam/Variable_34 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_35 (192, 192/192 params)
      training/Adam/Variable_36 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_37 (192, 192/192 params)
      training/Adam/Variable_38 (1x1x384x64, 24.58k/24.58k params)
      training/Adam/Variable_39 (64, 64/64 params)
      training/Adam/Variable_4 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_40 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_41 (256, 256/256 params)
      training/Adam/Variable_42 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_43 (256, 256/256 params)
      training/Adam/Variable_44 (1x1x512x64, 32.77k/32.77k params)
      training/Adam/Variable_45 (64, 64/64 params)
      training/Adam/Variable_46 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_47 (256, 256/256 params)
      training/Adam/Variable_48 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_49 (256, 256/256 params)
      training/Adam/Variable_5 (64, 64/64 params)
      training/Adam/Variable_50 (1x1x512x30, 15.36k/15.36k params)
      training/Adam/Variable_51 (30, 30/30 params)
      training/Adam/Variable_52 (3x3x3x64, 1.73k/1.73k params)
      training/Adam/Variable_53 (64, 64/64 params)
      training/Adam/Variable_54 (1x1x64x16, 1.02k/1.02k params)
      training/Adam/Variable_55 (16, 16/16 params)
      training/Adam/Variable_56 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_57 (64, 64/64 params)
      training/Adam/Variable_58 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_59 (64, 64/64 params)
      training/Adam/Variable_6 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_60 (1x1x128x16, 2.05k/2.05k params)
      training/Adam/Variable_61 (16, 16/16 params)
      training/Adam/Variable_62 (1x1x16x64, 1.02k/1.02k params)
      training/Adam/Variable_63 (64, 64/64 params)
      training/Adam/Variable_64 (3x3x16x64, 9.22k/9.22k params)
      training/Adam/Variable_65 (64, 64/64 params)
      training/Adam/Variable_66 (1x1x128x32, 4.10k/4.10k params)
      training/Adam/Variable_67 (32, 32/32 params)
      training/Adam/Variable_68 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_69 (128, 128/128 params)
      training/Adam/Variable_7 (64, 64/64 params)
      training/Adam/Variable_70 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_71 (128, 128/128 params)
      training/Adam/Variable_72 (1x1x256x32, 8.19k/8.19k params)
      training/Adam/Variable_73 (32, 32/32 params)
      training/Adam/Variable_74 (1x1x32x128, 4.10k/4.10k params)
      training/Adam/Variable_75 (128, 128/128 params)
      training/Adam/Variable_76 (3x3x32x128, 36.86k/36.86k params)
      training/Adam/Variable_77 (128, 128/128 params)
      training/Adam/Variable_78 (1x1x256x48, 12.29k/12.29k params)
      training/Adam/Variable_79 (48, 48/48 params)
      training/Adam/Variable_8 (1x1x128x16, 2.05k/2.05k params)
      training/Adam/Variable_80 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_81 (192, 192/192 params)
      training/Adam/Variable_82 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_83 (192, 192/192 params)
      training/Adam/Variable_84 (1x1x384x48, 18.43k/18.43k params)
      training/Adam/Variable_85 (48, 48/48 params)
      training/Adam/Variable_86 (1x1x48x192, 9.22k/9.22k params)
      training/Adam/Variable_87 (192, 192/192 params)
      training/Adam/Variable_88 (3x3x48x192, 82.94k/82.94k params)
      training/Adam/Variable_89 (192, 192/192 params)
      training/Adam/Variable_9 (16, 16/16 params)
      training/Adam/Variable_90 (1x1x384x64, 24.58k/24.58k params)
      training/Adam/Variable_91 (64, 64/64 params)
      training/Adam/Variable_92 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_93 (256, 256/256 params)
      training/Adam/Variable_94 (3x3x64x256, 147.46k/147.46k params)
      training/Adam/Variable_95 (256, 256/256 params)
      training/Adam/Variable_96 (1x1x512x64, 32.77k/32.77k params)
      training/Adam/Variable_97 (64, 64/64 params)
      training/Adam/Variable_98 (1x1x64x256, 16.38k/16.38k params)
      training/Adam/Variable_99 (256, 256/256 params)

======================End of Report==========================
